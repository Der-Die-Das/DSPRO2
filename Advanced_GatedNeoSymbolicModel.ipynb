{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e7fd77-bf50-4e51-90e7-7fa941809b44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: conceptnet-lite in /opt/conda/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: lmdb<2.0,>=1.0 in /opt/conda/lib/python3.12/site-packages (from conceptnet-lite) (1.6.2)\n",
      "Requirement already satisfied: peewee<4.0,>=3.10 in /opt/conda/lib/python3.12/site-packages (from conceptnet-lite) (3.18.1)\n",
      "Requirement already satisfied: pysmartdl<2.0,>=1.3 in /opt/conda/lib/python3.12/site-packages (from conceptnet-lite) (1.3.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets conceptnet-lite torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37547d8f-cf15-4470-a111-f825e1c73476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, get_cosine_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import conceptnet_lite\n",
    "import re\n",
    "\n",
    "conceptnet_lite.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb1c121-c172-41b1-862c-220ddec2b8a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load CommonsenseQA subset\n",
    "raw_train = load_dataset(\"tau/commonsense_qa\", split=\"train[:-1000]\")\n",
    "raw_valid = load_dataset(\"tau/commonsense_qa\", split=\"train[-1000:]\")\n",
    "raw_test = load_dataset(\"tau/commonsense_qa\", split=\"validation\")\n",
    "\n",
    "def preprocess(example):\n",
    "    inputs = []\n",
    "    for choice in example[\"choices\"][\"text\"]:\n",
    "        text = example[\"question\"] + \" \" + choice\n",
    "        inputs.append(text)\n",
    "    return {\"inputs\": inputs, \"answer_idx\": ord(example[\"answerKey\"]) - ord(\"A\")}\n",
    "\n",
    "train_data = [preprocess(ex) for ex in raw_train]\n",
    "valid_data = [preprocess(ex) for ex in raw_valid]\n",
    "test_data  = [preprocess(ex) for ex in raw_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fc0453-af17-45ae-b6a3-f8f46017a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conceptnet_facts(text):\n",
    "    words = re.findall(r'\\b\\w{4,}\\b', text.lower())  # filter short words\n",
    "    facts = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            concept = conceptnet_lite.Concept.get(label=word)\n",
    "            edges = concept.edges(direction='both')[:3]\n",
    "            for e in edges:\n",
    "                facts.append(f\"{e.start} {e.relation} {e.end}\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return \". \".join(facts[:5]) if facts else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236569b8-e619-4f04-9c9c-fef817f5a906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e4c4929bc747b5a59333847440dc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e600b9851275492d8bf103c326abab96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd01a57d4b145d8bb3de92f8dbe0609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db11278ff67849a58b38cbd6584cbc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335168935c7f4278a193d07844ff1312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a12ed816184b6cac37bf4e8e890287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "symbolic_tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "symbolic_encoder = AutoModel.from_pretrained(\"roberta-large\")\n",
    "\n",
    "def get_symbolic_embedding(fact_text, device):\n",
    "    if not fact_text:\n",
    "        return torch.zeros(1, 256).to(device)\n",
    "    tokens = symbolic_tokenizer(fact_text, truncation=True, padding=\"max_length\", max_length=16, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = symbolic_encoder(**tokens)\n",
    "        return out.last_hidden_state[:, 0, :256]  # CLS, first 256 dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82652f8-ff8d-479f-9450-618188d1e12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids, attention_masks, symbolic_vecs, labels = [], [], [], []\n",
    "    for ex in batch:\n",
    "        choice_ids, choice_masks, choice_syms = [], [], []\n",
    "        for inp in ex[\"inputs\"]:\n",
    "            tokens = symbolic_tokenizer(inp, truncation=True, padding=\"max_length\", max_length=32, return_tensors=\"pt\")\n",
    "            choice_ids.append(tokens[\"input_ids\"])\n",
    "            choice_masks.append(tokens[\"attention_mask\"])\n",
    "            symb_text = extract_conceptnet_facts(inp)\n",
    "            symb_vec = get_symbolic_embedding(symb_text, device='cpu')\n",
    "            choice_syms.append(symb_vec)\n",
    "        input_ids.append(torch.cat(choice_ids))\n",
    "        attention_masks.append(torch.cat(choice_masks))\n",
    "        symbolic_vecs.append(torch.cat(choice_syms))\n",
    "        labels.append(torch.tensor(ex[\"answer_idx\"]))\n",
    "    return (\n",
    "        torch.stack(input_ids),\n",
    "        torch.stack(attention_masks),\n",
    "        torch.stack(symbolic_vecs).squeeze(2),\n",
    "        torch.stack(labels)\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_data,  batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1764088-1836-47c7-b6aa-4c8d65c52ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuroSymbolicQA(nn.Module):\n",
    "    def __init__(self, model_name=\"roberta-large\", symbolic_dim=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.symbolic_proj = nn.Linear(symbolic_dim, symbolic_dim)\n",
    "        self.cross_attn = nn.MultiheadAttention(\n",
    "            embed_dim=self.encoder.config.hidden_size,\n",
    "            kdim=symbolic_dim,\n",
    "            vdim=symbolic_dim,\n",
    "            num_heads=4,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(self.encoder.config.hidden_size + symbolic_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.encoder.config.hidden_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, symbolic_vec):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        neural_out = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "        symbolic_out = self.symbolic_proj(symbolic_vec)\n",
    "        # Cross-attention: neural queries, symbolic keys/values\n",
    "        attn_out, _ = self.cross_attn(\n",
    "            neural_out.unsqueeze(1), \n",
    "            symbolic_out.unsqueeze(1), \n",
    "            symbolic_out.unsqueeze(1)\n",
    "        )\n",
    "        attn_out = attn_out.squeeze(1)\n",
    "        # Gated fusion\n",
    "        combined = torch.cat([neural_out, symbolic_out], dim=1)\n",
    "        gate = self.gate(combined)\n",
    "        gated_out = gate * neural_out + (1 - gate) * attn_out\n",
    "        gated_out = self.dropout(gated_out)\n",
    "        logits = self.classifier(gated_out)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2033775-9526-43ab-9ea0-c3b69a349071",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1/30: 100%|██████████| 63/63 [02:48<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 1.6094\n",
      "Validation Accuracy: 31.33%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 1.5879\n",
      "Validation Accuracy: 38.00%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 1.4424\n",
      "Validation Accuracy: 53.67%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Loss: 1.2115\n",
      "Validation Accuracy: 55.33%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Loss: 0.9348\n",
      "Validation Accuracy: 59.00%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Loss: 0.7055\n",
      "Validation Accuracy: 57.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Loss: 0.4822\n",
      "Validation Accuracy: 59.33%\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Loss: 0.3753\n",
      "Validation Accuracy: 59.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Loss: 0.3135\n",
      "Validation Accuracy: 57.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Loss: 0.2614\n",
      "Validation Accuracy: 58.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Loss: 0.2126\n",
      "Validation Accuracy: 58.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 63/63 [02:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Loss: 0.1859\n",
      "Validation Accuracy: 57.00%\n",
      "Early stopping.\n",
      "\n",
      "Best Validation Accuracy: 59.33%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NeuroSymbolicQA().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "num_epochs = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_val_acc = 0.0\n",
    "best_model_path = \"best_neurosymbolic_model.pt\"\n",
    "patience = 5\n",
    "epochs_no_improve = 0\n",
    "\n",
    "total_steps = num_epochs * len(train_loader)\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for input_ids, attn_masks, symb_vecs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attn_masks = attn_masks.to(device)\n",
    "        symb_vecs = symb_vecs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = []\n",
    "        for i in range(input_ids.size(1)):  # For each choice\n",
    "            logit = model(input_ids[:, i], attn_masks[:, i], symb_vecs[:, i])\n",
    "            logits.append(logit)\n",
    "        logits = torch.cat(logits, dim=1)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attn_masks, symb_vecs, labels in valid_loader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attn_masks = attn_masks.to(device)\n",
    "            symb_vecs = symb_vecs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = []\n",
    "            for i in range(input_ids.size(1)):\n",
    "                logit = model(input_ids[:, i], attn_masks[:, i], symb_vecs[:, i])\n",
    "                logits.append(logit)\n",
    "            logits = torch.cat(logits, dim=1)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Validation Accuracy: {val_acc:.2%}\")\n",
    "\n",
    "    # Early stopping & checkpoint\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(\"Best model saved.\")\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nBest Validation Accuracy: {best_val_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2172d5-c51c-4328-8fa6-9cd46bbf25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and evaluate on test set\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "yhat = []\n",
    "with torch.no_grad():\n",
    "    for input_ids, attn_masks, symb_vecs, labels in test_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attn_masks = attn_masks.to(device)\n",
    "        symb_vecs = symb_vecs.to(device)\n",
    "        logits = []\n",
    "        for i in range(input_ids.size(1)):\n",
    "            logit = model(input_ids[:, i], attn_masks[:, i], symb_vecs[:, i])\n",
    "            logits.append(logit)\n",
    "        logits = torch.cat(logits, dim=1)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        yhat.extend(preds.cpu().tolist())\n",
    "\n",
    "print(\"Test set predictions (yhat):\", yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
