{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776e9a91-a714-4de9-9cd6-450ebe8d2a22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.12/site-packages (3.8.7)\n",
      "Requirement already satisfied: torchdiffeq in /opt/conda/lib/python3.12/site-packages (0.2.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/conda/lib/python3.12/site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.12/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from spacy) (75.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from torchdiffeq) (2.6.0+cu124)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from torchdiffeq) (1.15.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets spacy torchdiffeq\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import requests\n",
    "import spacy\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from datasets import load_dataset\n",
    "from torchdiffeq import odeint\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b22b9e9-a92d-4ce4-a977-7b87eeca2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    roberta_model = \"roberta-base\"\n",
    "    max_length = 128\n",
    "    batch_size = 8\n",
    "    lstm_hidden = 256\n",
    "    diffusion_steps = 25\n",
    "    num_choices = 5\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cf8b20-a18c-4066-a743-493c2c4bdc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_conceptnet_edges_api(concept):\n",
    "    # Query ConceptNet for related concepts (edges) for a given concept\n",
    "    url = f\"http://api.conceptnet.io/c/en/{concept}\"\n",
    "    try:\n",
    "        obj = requests.get(url, timeout=3).json()\n",
    "        edges = []\n",
    "        for edge in obj.get('edges', []):\n",
    "            if '/en/' in edge['end']['@id']:\n",
    "                edges.append(edge['end']['label'])\n",
    "        return list(set(edges))\n",
    "    except Exception:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a192dd04-2b07-4e36-9a9a-fe0fa55c44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 1000/1000 [17:29<00:00,  1.05s/it]\n",
      "Preprocessing: 100%|██████████| 300/300 [05:13<00:00,  1.05s/it]\n",
      "Preprocessing: 100%|██████████| 100/100 [01:41<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(config.roberta_model)\n",
    "\n",
    "def augment_question_with_knowledge(question, question_concept):\n",
    "    # Use only question_concept for knowledge lookup, not the answer\n",
    "    q_concept = question_concept.replace(\" \", \"_\").lower()\n",
    "    q_knowledge = get_conceptnet_edges_api(q_concept)\n",
    "    q_knowledge_text = \" \".join(list(set(q_knowledge)))\n",
    "    # Augment the question with ConceptNet knowledge\n",
    "    aug_question = question + \" \" + q_knowledge_text if q_knowledge_text else question\n",
    "    return aug_question\n",
    "\n",
    "def preprocess_example(example):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    aug_question = augment_question_with_knowledge(example[\"question\"], example[\"question_concept\"])\n",
    "    for choice_text in example[\"choices\"][\"text\"]:\n",
    "        encoded = tokenizer(\n",
    "            aug_question, choice_text,\n",
    "            padding='max_length',\n",
    "            max_length=config.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'][0])\n",
    "        attention_mask.append(encoded['attention_mask'][0])\n",
    "    label = example[\"choices\"][\"label\"].index(example[\"answerKey\"]) if \"answerKey\" in example else -1\n",
    "    return {\n",
    "        \"input_ids\": torch.stack(input_ids),       # shape: (5, max_length)\n",
    "        \"attention_mask\": torch.stack(attention_mask),\n",
    "        \"label\": label\n",
    "    }\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    processed = []\n",
    "    for ex in tqdm(dataset, desc=\"Preprocessing\"):\n",
    "        processed.append(preprocess_example(ex))\n",
    "    return processed\n",
    "'''\n",
    "# Load and preprocess datasets\n",
    "raw_train = load_dataset(\"tau/commonsense_qa\", split=\"train[:-1000]\")\n",
    "raw_valid = load_dataset(\"tau/commonsense_qa\", split=\"train[-1000:]\")\n",
    "raw_test = load_dataset(\"tau/commonsense_qa\", split=\"validation\")\n",
    "'''\n",
    "# Load the full train split\n",
    "full_train = load_dataset(\"tau/commonsense_qa\", split=\"train\")\n",
    "\n",
    "# Create splits according to your specifications\n",
    "raw_train = full_train.select(range(1000))        # First 1000 samples\n",
    "raw_valid = full_train.select(range(1000, 1300))  # Next 300 samples (index 1000-1299)\n",
    "raw_test = full_train.select(range(1300, 1400))   # Next 100 samples (index 1300-1399)\n",
    "\n",
    "train_data = preprocess_dataset(raw_train)\n",
    "valid_data = preprocess_dataset(raw_valid)\n",
    "test_data = preprocess_dataset(raw_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91cb8ce-86f2-4002-ad71-241c966ceeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CSQADataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"input_ids\": item[\"input_ids\"],\n",
    "            \"attention_mask\": item[\"attention_mask\"],\n",
    "            \"label\": item[\"label\"]\n",
    "        }\n",
    "\n",
    "train_loader = DataLoader(CSQADataset(train_data), batch_size=config.batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(CSQADataset(valid_data), batch_size=config.batch_size)\n",
    "test_loader = DataLoader(CSQADataset(test_data), batch_size=config.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85833c7a-19cb-43d7-a47d-f68e72a274cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEDiffusion(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size*2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size*2, hidden_size)\n",
    "        )\n",
    "        self.time_steps = torch.linspace(0, 1, config.diffusion_steps)\n",
    "    \n",
    "    def odefunc(self, t, y):\n",
    "        return self.net(y)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch, seq, hidden = x.size()\n",
    "        # Use reshape instead of view for non-contiguous tensors\n",
    "        x_reshaped = x.reshape(-1, hidden)\n",
    "        refined = odeint(self.odefunc, x_reshaped, self.time_steps.to(x.device), method='dopri5')[-1]\n",
    "        return refined.reshape(batch, seq, hidden)\n",
    "\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(config.roberta_model)\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=768,\n",
    "            hidden_size=config.lstm_hidden // 2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.diffusion = ODEDiffusion(config.lstm_hidden)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config.lstm_hidden, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch, num_choices, seq = input_ids.size()\n",
    "        input_ids = input_ids.view(-1, seq)\n",
    "        attention_mask = attention_mask.view(-1, seq)\n",
    "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = outputs.last_hidden_state  # (batch*num_choices, seq, 768)\n",
    "        lstm_out, _ = self.bilstm(x)\n",
    "        diffused = self.diffusion(lstm_out)\n",
    "        pooled = diffused.mean(dim=1)  # (batch*num_choices, hidden)\n",
    "        logits = self.classifier(pooled)  # (batch*num_choices, 1)\n",
    "        logits = logits.view(batch, num_choices)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a320755-6ec2-4c55-a7f4-0338bd1bdb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(logits, labels):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == labels).float().mean().item()\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"input_ids\"].to(config.device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(config.device)\n",
    "        labels = batch[\"label\"].to(config.device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        acc = accuracy_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc\n",
    "    return total_loss / len(loader), total_acc / len(loader)\n",
    "\n",
    "def eval_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(config.device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(config.device)\n",
    "            labels = batch[\"label\"].to(config.device)\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            acc = accuracy_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "    return total_loss / len(loader), total_acc / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "657d509c-4f3b-4e06-bbbd-05ebe5ee3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.6064 | Test Acc: 0.1827\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = eval_epoch(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f5ad85-d43d-471e-8ed2-222c2ce60ecf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 1.6013 | Train Acc: 0.2340 | Val Loss: 1.6088 | Val Acc: 0.2829\n",
      "Epoch 2/15 | Train Loss: 1.5855 | Train Acc: 0.2890 | Val Loss: 1.5852 | Val Acc: 0.2829\n",
      "Epoch 3/15 | Train Loss: 1.4701 | Train Acc: 0.3660 | Val Loss: 1.5368 | Val Acc: 0.2895\n",
      "Epoch 4/15 | Train Loss: 1.2257 | Train Acc: 0.5180 | Val Loss: 1.5865 | Val Acc: 0.3750\n",
      "Epoch 5/15 | Train Loss: 0.8716 | Train Acc: 0.6940 | Val Loss: 1.7394 | Val Acc: 0.3717\n",
      "Epoch 6/15 | Train Loss: 0.5686 | Train Acc: 0.8050 | Val Loss: 2.0080 | Val Acc: 0.3289\n",
      "Epoch 7/15 | Train Loss: 0.3409 | Train Acc: 0.8850 | Val Loss: 2.4970 | Val Acc: 0.3355\n",
      "Epoch 8/15 | Train Loss: 0.2373 | Train Acc: 0.9230 | Val Loss: 3.5361 | Val Acc: 0.3289\n",
      "Early stopping triggered after 8 epochs due to no improvement in validation loss for 5 consecutive epochs.\n"
     ]
    }
   ],
   "source": [
    "epochs = 15  # Maximum number of epochs\n",
    "patience = 5  # Number of epochs to wait for improvement in validation loss\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = eval_epoch(model, valid_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs due to no improvement in validation loss for {patience} consecutive epochs.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf4e13-f92e-4e0d-be75-0162c23f02bf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
