{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0b5ba7d2-40f1-4458-a8a5-d434ed34db17",
   "metadata": {},
   "source": [
    "Link to experiment tracking-  https://wandb.ai/aditi-sharma-00073-hochschule-luzern"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24fbcd9c-14be-471b-86e7-2687f348269a",
   "metadata": {},
   "source": [
    "INTRODUCTION\n",
    "\n",
    "Project Title: CommonsenseQA Classification using Word Embeddings\n",
    "\n",
    "Description:\n",
    "This project implements and compares two architectures for solving the CommonsenseQA multiple-choice task. \n",
    "Each question has five possible answer choices (A–E), and the model must predict the most plausible answer \n",
    "based on commonsense reasoning.\n",
    "\n",
    "Architectures:\n",
    "1. Architecture 1: Pre-trained FastText word embeddings + 2-layer feedforward classifier\n",
    "2. Architecture 2: FastText embeddings + RNN (LSTM/GRU) + classifier\n",
    "\n",
    "Key Features:\n",
    "- Uses FastText pretrained embeddings (frozen or trainable)\n",
    "- Implements padding, batching, and DataLoader pipelines\n",
    "- Tracks experiments and metrics using Weights & Biases (W&B)\n",
    "- Evaluates using accuracy, F1 score, precision, recall, and confusion matrix\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e36b8b7-9071-405a-9d7c-e0e1bf4bd3fa",
   "metadata": {},
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb023dcf-0845-4774-b0d4-d17f9e0a1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.30.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3afc3fc-cbdd-4518-aab9-7bc36555cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43bd3b4-191f-4785-9bcd-b3d257ec5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.12/site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.12/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from wandb) (75.8.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.12/site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733ee70a-3096-4110-bd58-ee287947008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (1.26.4)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6a9a2-a07e-420a-840d-868d63e9ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load the pre-trained FastText model\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b174b42-d1c9-44fc-aaf1-db8a116e3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download tokenizer assets\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c7eac-a491-4ced-bafb-722b06752b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5293d93b-93c1-499a-9f68-b9b83192c6c3",
   "metadata": {},
   "source": [
    "Load the dataset in the notebook as per the required distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb7fc2-f211-494c-a177-feb7b260d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"tau/commonsense_qa\", split=\"train[:-1000]\")\n",
    "valid_dataset = load_dataset(\"tau/commonsense_qa\", split=\"train[-1000:]\")\n",
    "test_dataset = load_dataset(\"tau/commonsense_qa\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8f187-a71a-4ab5-ac36-0606980d6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.remove_columns(['id', 'question_concept'])\n",
    "valid_dataset = valid_dataset.remove_columns(['id', 'question_concept'])\n",
    "test_dataset = test_dataset.remove_columns(['id', 'question_concept'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50749551-5212-4d41-8c73-adfc919c611e",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47837b5b-a004-4de4-b4cc-01fe0c8aaf6d",
   "metadata": {},
   "source": [
    "1. Tokenization\n",
    "Word Tokenization: NLTK's word_tokenize() function splits a text into individual words while considering \n",
    "punctuation, special characters, and word boundaries, making it ideal for general-purpose tokenization.\n",
    "2. Lowercasing\n",
    "Preserving case sensitivity retains semantic distinctions critical for proper nouns, acronyms, and context-specific capitalization (e.g., \"US\" as a country vs. \"us\" as a pronoun).\n",
    "3. Stemming\n",
    "While stemming reduces words to roots (e.g., \"running\" → \"run\"), it risks oversimplification by stripping suffixes without considering context. Hence not done.\n",
    "4. Lemmatization\n",
    "Lemmatization maps words to their dictionary forms (e.g., \"better\" → \"good\") using linguistic context and part-of-speech tagging, ensuring accurate normalization without loss of meaning.\n",
    "5. Stopword/Punctuation Removal\n",
    "Stopwords (e.g., \"however,\" \"not\") and punctuation (e.g., question marks, quotation marks) provide critical syntactic, semantic, and tonal context. For instance, negation words (\"no,\" \"never\") are essential for sentiment analysis, while punctuation can define sentence boundaries or emphasize urgency (e.g., \"Help!\" vs. \"Help.\"). Not removed.\n",
    "6. Unknown Words\n",
    "While these terms won’t contribute to pre-trained embeddings, their presence allows to infer patterns from surrounding context. Not removed.\n",
    "7. Format cleaning (e.g. html-extracted text) \n",
    "Not required here, as text doesn't contain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd2ceb-c7b2-4814-9e57-dcc8cd80b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(dataset):\n",
    "    dataset['question'] = nltk.word_tokenize(dataset['question'])\n",
    "    dataset['choices']['text'] = [nltk.word_tokenize(choice) for choice in dataset['choices']['text']]\n",
    "    return dataset\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize)\n",
    "valid_dataset = valid_dataset.map(tokenize)\n",
    "test_dataset = test_dataset.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c91cdd-c0ba-42a4-bf38-7eaa86d2a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "for dataset in [train_dataset, valid_dataset, test_dataset]:\n",
    "    for example in dataset:\n",
    "        example['question'] = lemmatize_tokens(example['question']) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "872b34e4-d393-404a-b49c-091eecc51bb6",
   "metadata": {},
   "source": [
    "Batching:\n",
    "Instead of feeding one (question + 5 choices) sample at a time, we group multiple samples into a batch (e.g., batch_size = 32) to process them together.\n",
    "\n",
    "Input\n",
    "For Architecture 1 (Classifier):\n",
    "Shape is (batch_size × 5, 600) — one 600-dim vector per Q+choice pair.\n",
    "For Architecture 2 (RNN):\n",
    "Each batch becomes a tensor of shape:\n",
    "(batch_size × 5, max_seq_len, embedding_dim) — because each sample has 5 (Q+choice) pairs.\n",
    "\n",
    "Label\n",
    "Target label is a single integer from 0 to 4\n",
    "Used in nn.CrossEntropyLoss(), which expects:\n",
    "Logits shape: (batch_size, 5)\n",
    "Target shape: (batch_size,) with values ∈ {0,1,2,3,4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85537e4e-864f-4a68-9869-9f081d2c9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PART-1 : Word embeddings (fastText) together with a classifier (2-layer with ReLU \n",
    "non-linearity)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "adaa5371-5120-4f26-a685-12f3b9d88534",
   "metadata": {},
   "source": [
    "FastText Embeddings are used.\n",
    "popular choice for robustly processing diverse question-answer pairs in QA tasks.\n",
    "\n",
    "Vocabulary : Pretrained. Not my own\n",
    "\n",
    "Padding- Not needed in Model-1. (but needed for rnns- Model-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a668f-8d7a-449b-8223-9e80ce7c9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word, model=fasttext_model):\n",
    "    try:\n",
    "        return model[word]  # Retrieve the embedding for the word\n",
    "    except KeyError:\n",
    "        return np.zeros(300)  # Return a zero vector if the word is not in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60951ad-20ed-4323-b2d2-6066f2e95a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "\n",
    "    for item in data:\n",
    "        question = item['question']\n",
    "        choices = item['choices']['text']\n",
    "        answer_key = item['answerKey']\n",
    "        \n",
    "        # Compute average embedding for the question\n",
    "        question_embedding = np.mean([get_embedding(word) for word in question], axis=0)\n",
    "        \n",
    "        # Compute average embeddings for each choice\n",
    "        choice_embeddings = [np.mean([get_embedding(word) for word in choice], axis=0) for choice in choices]\n",
    "        \n",
    "        # Concatenate question embedding with each choice embedding\n",
    "        concatenated_inputs = [np.concatenate([question_embedding, choice_embedding]) for choice_embedding in choice_embeddings]\n",
    "        \n",
    "        # Map the answer to a label (A -> 0, B -> 1, ..., E -> 4)\n",
    "        label = ord(answer_key) - ord('A')  # 'A' maps to 0, 'B' to 1, etc.\n",
    "        \n",
    "        processed_data.append({\n",
    "            'inputs': concatenated_inputs,\n",
    "            'label': label\n",
    "        })\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "processed_train_data_1 = preprocess_data(train_dataset)\n",
    "print(f\"Processed data (example): {processed_train_data_1[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555935fa-4198-4dcf-9263-a9f83db22f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CommonsenseQADataset class for preparing dataset\n",
    "class CommonsenseQADataset_model1(Dataset):\n",
    "    def __init__(self, processed_data):\n",
    "        self.data = processed_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        inputs = item['inputs']  # List of 5 embeddings\n",
    "        label = item['label']    # Correct answer's index\n",
    "        \n",
    "        # Convert inputs (list of 5 embeddings) into a tensor\n",
    "        inputs_tensor = torch.tensor(inputs, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return inputs_tensor, label_tensor\n",
    "\n",
    "train_dataset = CommonsenseQADataset_model1(processed_train_data_1)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Check shapes for debugging\n",
    "for inputs, label in train_dataloader:\n",
    "    print(f\"Inputs shape: {inputs.shape}\")  # Should be (batch_size, 5, 600)\n",
    "    print(f\"Labels shape: {label.shape}\")  # Should be (batch_size,)\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "749a5fb0-e7c8-43e1-842e-494872124742",
   "metadata": {},
   "source": [
    "Model-1 Architecture"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc359ebc-0d1b-42a8-816e-b0738a7762b3",
   "metadata": {},
   "source": [
    "Preprocessing: Tokenize question and each choice, get FastText embeddings, and compute average for both.  \n",
    "Input to Model: Concatenate avg(question) + avg(choice) → 600-dim vector per option → shape (5, 600).  \n",
    "Model: 2-layer feedforward classifier with ReLU → outputs logits for each of 5 options.  \n",
    "Output: Softmax over logits → probabilities over 5 choices → predicted label (0–4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa06ddde-21ce-486b-a76c-d98e5c07eb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier model\n",
    "class ClassifierModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(ClassifierModel, self).__init__()\n",
    "        # Define the layers of the 2-layer fully connected (FC) network\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)  # Input to hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)  # Hidden to output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the input for each sample: (batch_size, 5, 600) -> (batch_size * 5, 600)\n",
    "        x = x.view(-1, 600)\n",
    "        # Pass the input through the first hidden layer with ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Pass through the second layer (output layer)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f04cee8-436e-4073-a452-8882b507c81b",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28766a0d-f7bd-432d-a143-b6fcaa5af8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "# Initialize W&B\n",
    "wandb.init(project='CQA_Model-1', name='train-1', config={\n",
    "    'epochs': 3,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-3,\n",
    "    'hidden_dim': 256,\n",
    "    'input_dim': 600,\n",
    "    'num_classes': 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e2d7b2-89ab-4fcb-83ea-7dc126c82965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model, loss function, and optimizer\n",
    "model = ClassifierModel(input_dim=600, hidden_dim=256, num_classes=5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with W&B tracking\n",
    "def train_with_wandb(model, dataloader, epochs=3):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device  # Get model's device\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            # Move data to model's device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Reshape and expand\n",
    "            inputs = inputs.view(-1, 600)  # [batch_size*5, 600]\n",
    "            expanded_labels = labels.repeat_interleave(5)  # [batch_size*5]\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = loss_fn(outputs, expanded_labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Accuracy calculation\n",
    "            outputs = outputs.view(-1, 5, 5)  # [batch_size, 5, 5]\n",
    "            _, predicted = outputs.max(dim=-1)  # Get predictions per option\n",
    "            correct = (predicted == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "            \n",
    "            correct_predictions += correct\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            # Backprop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Epoch metrics\n",
    "        epoch_loss = total_loss / len(dataloader)\n",
    "        epoch_acc = correct_predictions / total_samples\n",
    "        \n",
    "        wandb.log({'epoch': epoch+1, 'loss': epoch_loss, 'accuracy': epoch_acc})\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "train_with_wandb(model, train_dataloader, epochs=wandb.config.epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb86716a-ca99-48c8-bdf0-0c64cf9b76f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆█</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.38348</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>loss</td><td>1.6071</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train-1</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1/runs/gfl54fcp' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1/runs/gfl54fcp</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_003721-gfl54fcp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a81056d-250f-4dd7-a85d-0a4949aa0836",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0dd50-6c73-4b91-bf75-77a4569bbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_valid_data_1 = preprocess_data(valid_dataset)\n",
    "valid_dataset = CommonsenseQADataset_model1(processed_valid_data_1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5330f53-9390-4cad-b629-9c53ba57c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_model(model, valid_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "            \n",
    "            outputs = model(inputs.view(-1, 600))\n",
    "            outputs = outputs.view(-1, 5, 5)\n",
    "            _, predicted = outputs.max(dim=-1)\n",
    "            correct += (predicted == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d00e91ab-31cf-4513-b302-a43d8bd25607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Using cached optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from optuna) (1.15.1)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/conda/lib/python3.12/site-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/conda/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Using cached optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: colorlog, optuna\n",
      "Successfully installed colorlog-6.9.0 optuna-4.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89f986c6-d1b6-4bef-ac10-8a421e950c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36e40092-dfa8-48c6-a766-fb6e4431e41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 01:48:14,857] A new study created in memory with name: no-name-2f80c05e-fc4d-44b6-b4e9-e91c97be9728\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/vyqmapsj' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/vyqmapsj</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_014340-vyqmapsj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_014814-t0raj3qu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t0raj3qu' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t0raj3qu' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t0raj3qu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 Epoch 1/3\n",
      "Train Loss: 1.6096 | Val Loss: 1.6098\n",
      "Train Acc: 0.3449 | Val Acc: 0.3830\n",
      "Trial 0 Epoch 2/3\n",
      "Train Loss: 1.6089 | Val Loss: 1.6098\n",
      "Train Acc: 0.3263 | Val Acc: 0.4530\n",
      "Trial 0 Epoch 3/3\n",
      "Train Loss: 1.6083 | Val Loss: 1.6099\n",
      "Train Acc: 0.4028 | Val Acc: 0.3890\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>▃▁█</td></tr><tr><td>train_loss</td><td>█▄▁</td></tr><tr><td>val_accuracy</td><td>▁█▂</td></tr><tr><td>val_loss</td><td>▁▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.40281</td></tr><tr><td>train_loss</td><td>1.60832</td></tr><tr><td>val_accuracy</td><td>0.389</td></tr><tr><td>val_loss</td><td>1.60993</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t0raj3qu' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t0raj3qu</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_014814-t0raj3qu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 01:50:41,421] Trial 0 finished with value: 0.453 and parameters: {'lr': 0.00011023995848259353, 'batch_size': 64, 'hidden_dim': 227, 'weight_decay': 7.0184882405630934e-06}. Best is trial 0 with value: 0.453.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_015041-t7ya0kbq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t7ya0kbq' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t7ya0kbq' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t7ya0kbq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Epoch 1/3\n",
      "Train Loss: 1.6099 | Val Loss: 1.6096\n",
      "Train Acc: 0.2931 | Val Acc: 0.4240\n",
      "Trial 1 Epoch 2/3\n",
      "Train Loss: 1.6093 | Val Loss: 1.6097\n",
      "Train Acc: 0.3852 | Val Acc: 0.4430\n",
      "Trial 1 Epoch 3/3\n",
      "Train Loss: 1.6088 | Val Loss: 1.6098\n",
      "Train Acc: 0.4246 | Val Acc: 0.4010\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>▁▆█</td></tr><tr><td>train_loss</td><td>█▄▁</td></tr><tr><td>val_accuracy</td><td>▅█▁</td></tr><tr><td>val_loss</td><td>▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.42455</td></tr><tr><td>train_loss</td><td>1.60879</td></tr><tr><td>val_accuracy</td><td>0.401</td></tr><tr><td>val_loss</td><td>1.60978</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t7ya0kbq' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/t7ya0kbq</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_015041-t7ya0kbq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 01:53:06,523] Trial 1 finished with value: 0.443 and parameters: {'lr': 5.362187773798994e-05, 'batch_size': 64, 'hidden_dim': 246, 'weight_decay': 0.00017668069504100028}. Best is trial 0 with value: 0.453.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_015306-65nvtbix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/65nvtbix' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/65nvtbix' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/65nvtbix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Epoch 1/3\n",
      "Train Loss: 1.6109 | Val Loss: 1.6092\n",
      "Train Acc: 0.2245 | Val Acc: 0.3220\n",
      "Trial 2 Epoch 2/3\n",
      "Train Loss: 1.6099 | Val Loss: 1.6098\n",
      "Train Acc: 0.2267 | Val Acc: 0.2230\n",
      "Trial 2 Epoch 3/3\n",
      "Train Loss: 1.6104 | Val Loss: 1.6102\n",
      "Train Acc: 0.2852 | Val Acc: 0.2190\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>▁▁█</td></tr><tr><td>train_loss</td><td>█▁▄</td></tr><tr><td>val_accuracy</td><td>█▁▁</td></tr><tr><td>val_loss</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.28521</td></tr><tr><td>train_loss</td><td>1.61036</td></tr><tr><td>val_accuracy</td><td>0.219</td></tr><tr><td>val_loss</td><td>1.61021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/65nvtbix' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/65nvtbix</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_015306-65nvtbix/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 02:00:18,870] Trial 2 finished with value: 0.322 and parameters: {'lr': 0.00410839035959901, 'batch_size': 16, 'hidden_dim': 373, 'weight_decay': 2.883720402936802e-06}. Best is trial 0 with value: 0.453.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_020018-k54jobk2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/k54jobk2' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/k54jobk2' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/k54jobk2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Epoch 1/3\n",
      "Train Loss: 1.6100 | Val Loss: 1.6108\n",
      "Train Acc: 0.2333 | Val Acc: 0.3180\n",
      "Trial 3 Epoch 2/3\n",
      "Train Loss: 1.6093 | Val Loss: 1.6102\n",
      "Train Acc: 0.3892 | Val Acc: 0.4010\n",
      "Trial 3 Epoch 3/3\n",
      "Train Loss: 1.6089 | Val Loss: 1.6100\n",
      "Train Acc: 0.3760 | Val Acc: 0.3420\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>▁█▇</td></tr><tr><td>train_loss</td><td>█▄▁</td></tr><tr><td>val_accuracy</td><td>▁█▃</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.37604</td></tr><tr><td>train_loss</td><td>1.60891</td></tr><tr><td>val_accuracy</td><td>0.342</td></tr><tr><td>val_loss</td><td>1.60996</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/k54jobk2' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna/runs/k54jobk2</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_020018-k54jobk2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 02:02:43,720] Trial 3 finished with value: 0.401 and parameters: {'lr': 4.038254620795372e-05, 'batch_size': 64, 'hidden_dim': 362, 'weight_decay': 7.131331828731729e-05}. Best is trial 0 with value: 0.453.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('lr', 1e-5, 1e-2, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'hidden_dim': trial.suggest_int('hidden_dim', 128, 512),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "    }\n",
    "    \n",
    "    # Initialize W&B\n",
    "    wandb.init(\n",
    "        project='CQA_Model-1_Optuna',\n",
    "        name=f'trial_{trial.number}',\n",
    "        config={\n",
    "            **params,\n",
    "            'epochs': 3,\n",
    "            'input_dim': 600,\n",
    "            'num_classes': 5\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    # Create loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ClassifierModel(\n",
    "        input_dim=600,\n",
    "        hidden_dim=params['hidden_dim'],\n",
    "        num_classes=5\n",
    "    ).to('cuda')\n",
    "    \n",
    "    # Optimizer and loss\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=params['learning_rate'],\n",
    "        weight_decay=params['weight_decay']\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to('cuda', non_blocking=True)\n",
    "            labels = labels.to('cuda', non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs.view(-1, 600))\n",
    "            expanded_labels = labels.repeat_interleave(5)\n",
    "            loss = loss_fn(outputs, expanded_labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            with torch.no_grad():\n",
    "                outputs = outputs.view(-1, 5, 5)\n",
    "                _, predicted = outputs.max(dim=-1)\n",
    "                correct = (predicted == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_correct += correct\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs = inputs.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "                \n",
    "                outputs = model(inputs.view(-1, 600))\n",
    "                expanded_labels = labels.repeat_interleave(5)\n",
    "                \n",
    "                # Calculate validation loss\n",
    "                loss = loss_fn(outputs, expanded_labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                outputs = outputs.view(-1, 5, 5)\n",
    "                _, predicted = outputs.max(dim=-1)\n",
    "                correct = (predicted == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "                \n",
    "                val_correct += correct\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_loss = val_loss / len(valid_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Log metrics\n",
    "        wandb.log({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_accuracy': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"Trial {trial.number} Epoch {epoch+1}/3\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Track best validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "    wandb.finish()\n",
    "    return best_val_acc\n",
    "\n",
    "# Run study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=4)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3cc3a1a-971d-404d-b31f-fdeff221783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Val Accuracy: 0.4530\n",
      "  Params: \n",
      "    lr: 0.00011023995848259353\n",
      "    batch_size: 64\n",
      "    hidden_dim: 227\n",
      "    weight_decay: 7.0184882405630934e-06\n"
     ]
    }
   ],
   "source": [
    "#  Best results\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Val Accuracy: {trial.value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4aefdc77-e7dd-4e8c-a75e-1487f81575d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_020243-rbc0vdo2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Final/runs/rbc0vdo2' target=\"_blank\">bumbling-dawn-1</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Final' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Final/runs/rbc0vdo2' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Final/runs/rbc0vdo2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 1.6098 | Acc: 0.3146\n",
      "Epoch 2/3 | Loss: 1.6089 | Acc: 0.3811\n",
      "Epoch 3/3 | Loss: 1.6083 | Acc: 0.3330\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mbumbling-dawn-1\u001b[0m at: \u001b[34mhttps://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-1_Final/runs/rbc0vdo2\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250408_020243-rbc0vdo2/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best params\n",
    "best_params = study.best_params\n",
    "wandb.init(project='CQA_Model-1_Final', config={\n",
    "    **best_params,\n",
    "    'epochs': 3,\n",
    "    'input_dim': 600,\n",
    "    'num_classes': 5\n",
    "})\n",
    "\n",
    "final_model = ClassifierModel(\n",
    "    input_dim=600,\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    num_classes=5\n",
    ").to('cuda')\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    final_model.parameters(),\n",
    "    lr=best_params['lr'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "# Use entire training data (train + valid) for final training\n",
    "full_train_dataset = torch.utils.data.ConcatDataset([train_dataset, valid_dataset])\n",
    "full_train_loader = DataLoader(\n",
    "    full_train_dataset,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    shuffle=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "train_with_wandb(final_model, full_train_loader, epochs=3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f726115-6a51-4b86-b7c4-dcb4ddbe52fe",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15ff31-8433-49a3-b9c1-b9e7df6466ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_data_1 = preprocess_data(test_dataset)\n",
    "test_dataset = CommonsenseQADataset_model1(processed_test_data_1)  \n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "971b3720-1d13-4c4a-8ef9-8b6c25658929",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ocEROduodio",
    "outputId": "b4b8b5c7-2bf5-4170-a6a0-a336859037fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2056\n",
      "Precision: 0.0720\n",
      "Recall: 0.1970\n",
      "F1 Score: 0.0713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# Prediction on validation/test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.to('cuda')  # Move the model to the GPU\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to('cuda'), targets.to('cuda')  # Move inputs and targets to GPU\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1, 5, 5) # Reshape outputs to (batch_size, 5, 5)\n",
    "        _, predicted = outputs.max(dim=-1) # Get predictions per option\n",
    "\n",
    "        # Get the prediction for the correct choice for each example in the batch\n",
    "        predicted_labels = predicted[torch.arange(predicted.shape[0]), targets]\n",
    "\n",
    "        y_true.extend(targets.cpu().numpy())\n",
    "        y_pred.extend(predicted_labels.cpu().numpy())  # Extend with per-example predictions\n",
    "\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')  # Use 'binary' or 'micro' based on task\n",
    "\n",
    "# Log to W&B\n",
    "wandb.log({\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1\n",
    "})\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24491900-1b5a-4285-b8ee-fbec29b0e380",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H1aHULZzriPk",
    "outputId": "b3022c76-71b9-4628-ac9f-4b6646369fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: True Label = 3, Predicted Label = 1\n",
      "Sample 2: True Label = 3, Predicted Label = 1\n",
      "Sample 3: True Label = 0, Predicted Label = 1\n",
      "Sample 4: True Label = 3, Predicted Label = 1\n",
      "Sample 5: True Label = 0, Predicted Label = 1\n",
      "Sample 6: True Label = 0, Predicted Label = 1\n",
      "Sample 7: True Label = 2, Predicted Label = 1\n",
      "Sample 8: True Label = 2, Predicted Label = 1\n",
      "Sample 9: True Label = 0, Predicted Label = 1\n",
      "Sample 10: True Label = 3, Predicted Label = 1\n"
     ]
    }
   ],
   "source": [
    "misclassified = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_dataloader:\n",
    "        inputs, targets = inputs.to('cuda'), targets.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1, 5, 5) # Reshape outputs to (batch_size, 5, 5)\n",
    "        _, predicted = outputs.max(dim=-1) # Get predictions per option (shape: [batch_size, 5])\n",
    "\n",
    "        # Get the prediction corresponding to the true label for each example\n",
    "        predicted_labels = predicted[torch.arange(predicted.shape[0]), targets]\n",
    "\n",
    "        # Compare the selected prediction with the true label\n",
    "        incorrect_indices = (predicted_labels != targets).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        for idx in incorrect_indices:\n",
    "            # Store the single predicted label (corresponding to the true label)\n",
    "            misclassified.append((inputs[idx].cpu().numpy(), targets[idx].cpu().numpy(), predicted_labels[idx].cpu().numpy()))\n",
    "\n",
    "for i, (input_sample, true_label, pred_label) in enumerate(misclassified[:10]):  # Display top 10 misclassified samples\n",
    "    print(f\"Sample {i + 1}: True Label = {true_label}, Predicted Label = {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f3125db-8f04-403e-b76b-40047af98bed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "81NylwXYozbo",
    "outputId": "e00b6032-ba01-4865-86b6-c0822e8c6b34"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZdNJREFUeJzt3Xd4FFXbx/HfptNSaIFQIjUQqoAlgBSB0EJVugIWQAQsQUB6lfiIEkQQrIAKKk1UBKQpPEgo0lHpUVQIJUAiEBJI5v2Dh32NA5JANrPJfj9ec11m6r17dHLnPmfO2AzDMAQAAAD8jZvVAQAAAMD5kCQCAADAhCQRAAAAJiSJAAAAMCFJBAAAgAlJIgAAAExIEgEAAGBCkggAAAATkkQAAACYkCQC+FeHDx9WeHi4/Pz8ZLPZtGzZsiw9/6+//iqbzaa5c+dm6XlzskaNGqlRo0ZWhwHAxZEkAjnA0aNH1a9fP5UtW1Y+Pj7y9fVVvXr19OabbyopKcmh1+7Vq5f27dunV155RR9//LHq1Knj0Otlp969e8tms8nX1/em3+Phw4dls9lks9n0+uuvZ/r8J06c0Lhx47R79+4siBYAspeH1QEA+HfffPONOnXqJG9vb/Xs2VNVq1ZVSkqKNm3apCFDhuinn37Su+++65BrJyUlKSYmRiNHjtTAgQMdco3g4GAlJSXJ09PTIee/HQ8PD12+fFlff/21OnfunG7b/Pnz5ePjoytXrtzRuU+cOKHx48frnnvuUc2aNTN83OrVq+/oegCQlUgSAScWGxurrl27Kjg4WOvXr1fx4sXt2wYMGKAjR47om2++cdj1z5w5I0ny9/d32DVsNpt8fHwcdv7b8fb2Vr169fTpp5+aksQFCxaodevWWrJkSbbEcvnyZeXNm1deXl7Zcj0A+Dd0NwNO7LXXXtPFixf1wQcfpEsQbyhfvryef/55+8/Xrl3TxIkTVa5cOXl7e+uee+7RiBEjlJycnO64e+65RxEREdq0aZPuv/9++fj4qGzZsvroo4/s+4wbN07BwcGSpCFDhshms+mee+6RdL2b9sa//924ceNks9nSrVuzZo3q168vf39/5c+fXyEhIRoxYoR9+63GJK5fv14PPfSQ8uXLJ39/f7Vr106//PLLTa935MgR9e7dW/7+/vLz89MTTzyhy5cv3/qL/Yfu3btr5cqVunDhgn3d9u3bdfjwYXXv3t20/7lz5/TSSy+pWrVqyp8/v3x9fdWyZUvt2bPHvs/333+v++67T5L0xBNP2Lutb3zORo0aqWrVqtqxY4caNGigvHnz2r+Xf45J7NWrl3x8fEyfv3nz5goICNCJEycy/FkBIKNIEgEn9vXXX6ts2bKqW7duhvZ/+umnNWbMGNWqVUvR0dFq2LChoqKi1LVrV9O+R44c0aOPPqpmzZrpjTfeUEBAgHr37q2ffvpJktSxY0dFR0dLkrp166aPP/5Y06ZNy1T8P/30kyIiIpScnKwJEybojTfeUNu2bfXDDz/863Fr165V8+bNdfr0aY0bN06RkZHavHmz6tWrp19//dW0f+fOnfXXX38pKipKnTt31ty5czV+/PgMx9mxY0fZbDYtXbrUvm7BggWqVKmSatWqZdr/2LFjWrZsmSIiIjR16lQNGTJE+/btU8OGDe0JW+XKlTVhwgRJUt++ffXxxx/r448/VoMGDezniY+PV8uWLVWzZk1NmzZNjRs3vml8b775pooUKaJevXopNTVVkvTOO+9o9erVeuuttxQUFJThzwoAGWYAcEoJCQmGJKNdu3YZ2n/37t2GJOPpp59Ot/6ll14yJBnr16+3rwsODjYkGRs3brSvO336tOHt7W0MHjzYvi42NtaQZEyZMiXdOXv16mUEBwebYhg7dqzx99tKdHS0Ick4c+bMLeO+cY05c+bY19WsWdMoWrSoER8fb1+3Z88ew83NzejZs6fpek8++WS6c3bo0MEoVKjQLa/598+RL18+wzAM49FHHzWaNGliGIZhpKamGsWKFTPGjx9/0+/gypUrRmpqqulzeHt7GxMmTLCv2759u+mz3dCwYUNDkjF79uybbmvYsGG6dd9++60hyZg0aZJx7NgxI3/+/Eb79u1v+xkB4E5RSQScVGJioiSpQIECGdp/xYoVkqTIyMh06wcPHixJprGLoaGheuihh+w/FylSRCEhITp27Ngdx/xPN8Yyfvnll0pLS8vQMSdPntTu3bvVu3dvFSxY0L6+evXqatasmf1z/t0zzzyT7ueHHnpI8fHx9u8wI7p3767vv/9ecXFxWr9+veLi4m7a1SxdH8fo5nb99pmamqr4+Hh7V/rOnTszfE1vb2898cQTGdo3PDxc/fr104QJE9SxY0f5+PjonXfeyfC1ACCzSBIBJ+Xr6ytJ+uuvvzK0/2+//SY3NzeVL18+3fpixYrJ399fv/32W7r1pUuXNp0jICBA58+fv8OIzbp06aJ69erp6aefVmBgoLp27aqFCxf+a8J4I86QkBDTtsqVK+vs2bO6dOlSuvX//CwBAQGSlKnP0qpVKxUoUECff/655s+fr/vuu8/0Xd6Qlpam6OhoVahQQd7e3ipcuLCKFCmivXv3KiEhIcPXLFGiRKYeUnn99ddVsGBB7d69W9OnT1fRokUzfCwAZBZJIuCkfH19FRQUpP3792fquH8+OHIr7u7uN11vGMYdX+PGeLkb8uTJo40bN2rt2rV6/PHHtXfvXnXp0kXNmjUz7Xs37uaz3ODt7a2OHTtq3rx5+uKLL25ZRZSkyZMnKzIyUg0aNNAnn3yib7/9VmvWrFGVKlUyXDGVrn8/mbFr1y6dPn1akrRv375MHQsAmUWSCDixiIgIHT16VDExMbfdNzg4WGlpaTp8+HC69adOndKFCxfsTypnhYCAgHRPAt/wz2qlJLm5ualJkyaaOnWqfv75Z73yyitav369vvvuu5ue+0acBw8eNG07cOCAChcurHz58t3dB7iF7t27a9euXfrrr79u+rDPDYsXL1bjxo31wQcfqGvXrgoPD1fTpk1N30lGE/aMuHTpkp544gmFhoaqb9++eu2117R9+/YsOz8A/BNJIuDEhg4dqnz58unpp5/WqVOnTNuPHj2qN998U9L17lJJpieQp06dKklq3bp1lsVVrlw5JSQkaO/evfZ1J0+e1BdffJFuv3PnzpmOvTGp9D+n5bmhePHiqlmzpubNm5cu6dq/f79Wr15t/5yO0LhxY02cOFEzZsxQsWLFbrmfu7u7qUq5aNEi/fnnn+nW3Uhmb5ZQZ9awYcN0/PhxzZs3T1OnTtU999yjXr163fJ7BIC7xWTagBMrV66cFixYoC5duqhy5crp3riyefNmLVq0SL1795Yk1ahRQ7169dK7776rCxcuqGHDhtq2bZvmzZun9u3b33J6lTvRtWtXDRs2TB06dNBzzz2ny5cva9asWapYsWK6BzcmTJigjRs3qnXr1goODtbp06f19ttvq2TJkqpfv/4tzz9lyhS1bNlSYWFheuqpp5SUlKS33npLfn5+GjduXJZ9jn9yc3PTqFGjbrtfRESEJkyYoCeeeEJ169bVvn37NH/+fJUtWzbdfuXKlZO/v79mz56tAgUKKF++fHrggQdUpkyZTMW1fv16vf322xo7dqx9Sp45c+aoUaNGGj16tF577bVMnQ8AMsTip6sBZMChQ4eMPn36GPfcc4/h5eVlFChQwKhXr57x1ltvGVeuXLHvd/XqVWP8+PFGmTJlDE9PT6NUqVLG8OHD0+1jGNenwGndurXpOv+ceuVWU+AYhmGsXr3aqFq1quHl5WWEhIQYn3zyiWkKnHXr1hnt2rUzgoKCDC8vLyMoKMjo1q2bcejQIdM1/jlNzNq1a4169eoZefLkMXx9fY02bdoYP//8c7p9blzvn1PszJkzx5BkxMbG3vI7NYz0U+Dcyq2mwBk8eLBRvHhxI0+ePEa9evWMmJiYm05d8+WXXxqhoaGGh4dHus/ZsGFDo0qVKje95t/Pk5iYaAQHBxu1atUyrl69mm6/F1980XBzczNiYmL+9TMAwJ2wGUYmRnYDAADAJTAmEQAAACYkiQAAADAhSQQAAIAJSSIAAABMSBIBAABgQpIIAAAAE5JEAAAAmOTKN65cuWZ1BLghoNFoq0PA35z7bqLVIeB/svC1zkCu4WNhVpLn3oEOO3fSrhkOO7cjUUkEAACASa6sJAIAAGSKjbrZP5EkAgAAMAbEhLQZAAAAJlQSAQAA6G424RsBAACACZVEAAAAxiSaUEkEAACACZVEAAAAxiSa8I0AAADAhEoiAAAAYxJNSBIBAADobjbhGwEAAIAJlUQAAAC6m02oJAIAAMCESiIAAABjEk34RgAAAGBCJREAAIAxiSZUEgEAAGBCJREAAIAxiSYkiQAAAHQ3m5A2AwAAwMTSSmJKSoqWLVummJgYxcXFSZKKFSumunXrql27dvLy8rIyPAAA4Crobjax7Bs5cuSIKleurF69emnXrl1KS0tTWlqadu3apZ49e6pKlSo6cuSIVeEBAAC4NMsqif3791e1atW0a9cu+fr6ptuWmJionj17asCAAfr2228tihAAALgMKokmliWJP/zwg7Zt22ZKECXJ19dXEydO1AMPPGBBZAAAALAsbfb399evv/56y+2//vqr/P39sy0eAADgwtxsjltyKMsqiU8//bR69uyp0aNHq0mTJgoMDJQknTp1SuvWrdOkSZM0aNAgq8IDAABwaZYliRMmTFC+fPk0ZcoUDR48WLb/zU9kGIaKFSumYcOGaejQoVaFBwAAXAljEk0snQJn2LBhGjZsmGJjY9NNgVOmTBkrwwIAAK6GybRNnOKNK2XKlCExBAAAcCJOkSQCAABYiu5mE74RAAAAmFBJBAAAYEyiCZVEAAAAmFieJK5atUqbNm2y/zxz5kzVrFlT3bt31/nz5y2MDAAAuAybm+OWHMryyIcMGaLExERJ0r59+zR48GC1atVKsbGxioyMtDg6AAAA12T5mMTY2FiFhoZKkpYsWaKIiAhNnjxZO3fuVKtWrSyODgAAuATGJJpYXkn08vLS5cuXJUlr165VeHi4JKlgwYL2CiMAAIBD0d1sYnklsX79+oqMjFS9evW0bds2ff7555KkQ4cOqWTJkhZHBwAA4JosT29nzJghDw8PLV68WLNmzVKJEiUkSStXrlSLFi0sjs4any2Yr5bNHtZ991ZTj66dtG/vXqtDynVeeqyBNr3XT6dXj9JvXw/TwsndVaFU4XT7vDWkrX76/EWdWzdGx79+WQujuqti6fT71K5UQium9dbJlSN0YuUIffVGT1UrXyw7P4pL2PHjdj034Bk1a1xfNauGaP26tVaH5PK4TzkP2iKL2GyOW3Ioy5PE0qVLa/ny5dqzZ4+eeuop+/ro6GhNnz7dwsissWrlCr3+WpT6PTtAny36QiEhldS/31OKj4+3OrRc5aF779HspdvUsN+7inhxnjw83LQ8upfy+nja99l18IT6Tl6qmj2mq+3gebLZbFoe3Utubtf/h8+Xx0tfvtFTv59KUIO+76rJs+/r4uUUffVGT3m4W/6/Vq6SlHRZFUNCNHzkWKtDgbhPORPaAo5k+W+ynTt3at++ffafv/zyS7Vv314jRoxQSkqKhZFZ4+N5c9Tx0c5q3+ERlStfXqPGjpePj4+WLV1idWi5SrvBH+mTlbv0S+xp7TsSp76Tl6p0MX/dGxJk3+fDr37UD3t+0/G4C9p96KTGv7dWpQL9FVzMX5IUUrqwCvnl1cQP1unw72f1S+xpvTLnOxUrVECl/7cPskb9hxpq4HMv6uGmzawOBeI+5UxoiyzEmEQTyyPv16+fDh06JEk6duyYunbtqrx582rRokUaOnSoxdFlr6spKfrl55/0YFhd+zo3Nzc9+GBd7d2zy8LIcj/ffD6SpPOJSTfdntfHUz1b1VLsiXP64/T1B6oOHT+rsxcuqVdEbXl6uMvHy0O9I2rpl9jT+i3uQnaFDmQr7lPOg7aAo1n+4MqhQ4dUs2ZNSdKiRYvUoEEDLViwQD/88IO6du2qadOm/evxycnJSk5OTrfOcPeWt7e3gyJ2nPMXzis1NVWFChVKt75QoUKKjT1mUVS5n81m05TnWmnz3t/0c+zpdNv6drhfr/QPV/683jr42xm1fmGurl5LlSRdTEpR80EfamFUdw3v1UiSdOSPeLWNnKfU1LTs/hhAtuA+5TxoiyyWg8cOOorllUTDMJSWdv0X6tq1a+1zI5YqVUpnz5697fFRUVHy8/NLt0z5T5RDY0buMi0yQlXKFlXPsQtN2z5bvUcPPvm2mg54X4d/j9cnE7vI2+v631Y+Xh6aPby9YvYdV8N+7+rhZ9/Tz8dOa+mUx+XjZfnfXwAA3BXLf5PVqVNHkyZNUtOmTbVhwwbNmjVL0vVJtgMDA297/PDhw01vZjHcc14VUZIC/APk7u5uGnAcHx+vwoUL3+Io3I3oF1urVd0QNR34vv48Y56XM/FSshIvJevoH+e07ac/dHLlCLVrUFkL1+5Tl2bVVbpYgBr2e0+GYUiSeo1fpJMrR6jNQ5W1aN0+0/mAnI77lPOgLbJYDh476CiWfyPTpk3Tzp07NXDgQI0cOVLly5eXJC1evFh169a9zdGSt7e3fH190y05satZkjy9vFQ5tIq2bomxr0tLS9PWrTGqXuNeCyPLnaJfbK22DULV4vkP9dvJC7fd/8ZMBl6e1/+2yuvjqbQ0w54gSlKacf3nG09AA7kN9ynnQVtkMR5cMbG8kli9evV0TzffMGXKFLm7u1sQkbUe7/WERo8YpipVqqpqter65ON5SkpKUvsOHa0OLVeZNjhCXZpWV6fhC3TxcooCC+aXJCVcvKIrKdd0T1CAHn24mtZtP6KzFy6pRBFfDX6sgZKSr+nbmOsPWq3bflSTn22uaYMjNGvxVrm52fRSj4d0LTVNG3YyHigrXb58ScePH7f//Oeff+jAgV/k5+en4sWD/uVIOAL3KedBW8CRLE8Sb8XHx8fqECzRomUrnT93Tm/PmK6zZ88opFJlvf3O+ypE10GW6tfhAUnSmhlPpVvf55Wl+mTlLiUnX1O9GsEa2DlMAQV8dPrcJW3a86saP/Oezly4JOn6082PDJuvkU821vez+yjNMLTn0Em1e+kjxcVfzPbPlJv9tH+/+jzZ0/7zG69dH3fcpl0HTXzlVavCclncp5wHbZGFeHDFxGb8va/MAqmpqYqOjtbChQt1/Phx09yI586dy/Q5r1zLquhwtwIajbY6BPzNue8mWh0C/offR4CZj4WlqzxtZzns3Elf9XfYuR3J8o7y8ePHa+rUqerSpYsSEhIUGRmpjh07ys3NTePGjbM6PAAA4AoYk2hieeTz58/Xe++9p8GDB8vDw0PdunXT+++/rzFjxmjLli1WhwcAAOCSLE8S4+LiVK1aNUlS/vz5lZCQIEmKiIjQN998Y2VoAADAVdyYwsIRSw5leZJYsmRJnTx5UpJUrlw5rV69WpK0ffv2HDuVDQAAQE5neZLYoUMHrVu3TpI0aNAgjR49WhUqVFDPnj315JNPWhwdAABwCYxJNLF8CpxXX/3/6Su6dOmi0qVLKyYmRhUqVFCbNm0sjAwAALiMHNwt7CiWJ4n/FBYWprCwMKvDAAAAcGmWJIlfffVVhvdt27atAyMBAACQbFQSTSxJEtu3b5+h/Ww2m1JTUx0bDAAAAEwsSRLT0tKsuCwAAMBNUUk0y7mP3AAAAMBhLEsS169fr9DQUCUmJpq2JSQkqEqVKtq4caMFkQEAAJdjc+CSQ1mWJE6bNk19+vSRr6+vaZufn5/69eun6OhoCyIDAACAZUninj171KJFi1tuDw8P144dO7IxIgAA4KpsNpvDlpzKsnkST506JU9Pz1tu9/Dw0JkzZ7IxIgAA4KpycjLnKJZVEkuUKKH9+/ffcvvevXtVvHjxbIwIAAAAN1iWJLZq1UqjR4/WlStXTNuSkpI0duxYRUREWBAZAABwNXQ3m1nW3Txq1CgtXbpUFStW1MCBAxUSEiJJOnDggGbOnKnU1FSNHDnSqvAAAABcmmVJYmBgoDZv3qz+/ftr+PDhMgxD0vVMvnnz5po5c6YCAwOtCg8AALiQnFzxcxTLkkRJCg4O1ooVK3T+/HkdOXJEhmGoQoUKCggIsDIsAAAAl2dpknhDQECA7rvvPqvDAAAAropCogmv5QMAAICJU1QSAQAArMSYRDMqiQAAADChkggAAFwelUQzkkQAAODySBLN6G4GAACACZVEAADg8qgkmlFJBAAAgAmVRAAAAAqJJlQSAQAAYEIlEQAAuDzGJJpRSQQAAIAJlUQAAODyqCSakSQCAACXR5JoRnczAACAk4iKitJ9992nAgUKqGjRomrfvr0OHjyYbp8rV65owIABKlSokPLnz69HHnlEp06dSrfP8ePH1bp1a+XNm1dFixbVkCFDdO3atUzFQpIIAABgc+CSCRs2bNCAAQO0ZcsWrVmzRlevXlV4eLguXbpk3+fFF1/U119/rUWLFmnDhg06ceKEOnbsaN+empqq1q1bKyUlRZs3b9a8efM0d+5cjRkzJnNfiWEYRubCd35XMpcow4ECGo22OgT8zbnvJlodAv6Hni3AzMfCQXBFn1rosHOf/qDzHR975swZFS1aVBs2bFCDBg2UkJCgIkWKaMGCBXr00UclSQcOHFDlypUVExOjBx98UCtXrlRERIROnDihwMBASdLs2bM1bNgwnTlzRl5eXhm6NpVEAADg8mw2m8OW5ORkJSYmpluSk5MzFFdCQoIkqWDBgpKkHTt26OrVq2ratKl9n0qVKql06dKKiYmRJMXExKhatWr2BFGSmjdvrsTERP30008Z/k5IEgEAABwoKipKfn5+6ZaoqKjbHpeWlqYXXnhB9erVU9WqVSVJcXFx8vLykr+/f7p9AwMDFRcXZ9/n7wnije03tmUUTzfDsS6dtzoC/E1qWq4bXZJjebjT3+wsct+gK9wJRz7dPHz4cEVGRqZb5+3tfdvjBgwYoP3792vTpk2OCu1fkSQCAAA4kLe3d4aSwr8bOHCgli9fro0bN6pkyZL29cWKFVNKSoouXLiQrpp46tQpFStWzL7Ptm3b0p3vxtPPN/bJCLqbAQCAy3PkmMTMMAxDAwcO1BdffKH169erTJky6bbXrl1bnp6eWrdunX3dwYMHdfz4cYWFhUmSwsLCtG/fPp0+fdq+z5o1a+Tr66vQ0NAMx0IlEQAAuDxnmUx7wIABWrBggb788ksVKFDAPobQz89PefLkkZ+fn5566ilFRkaqYMGC8vX11aBBgxQWFqYHH3xQkhQeHq7Q0FA9/vjjeu211xQXF6dRo0ZpwIABmapokiQCAAA4iVmzZkmSGjVqlG79nDlz1Lt3b0lSdHS03Nzc9Mgjjyg5OVnNmzfX22+/bd/X3d1dy5cvV//+/RUWFqZ8+fKpV69emjBhQqZiYZ5EOFTAfQOtDgF/c2bLW1aHgP/hwRXnkft+C+ZceTytu3bQM0sddu4TszveficnxJhEAAAAmNDdDAAAXJ6zjEl0JlQSAQAAYEIlEQAAuDwqiWZUEgEAAGBCJREAALg8KolmJIkAAADkiCZ0NwMAAMCESiIAAHB5dDebUUkEAACACZVEAADg8qgkmlFJBAAAgAmVRAAA4PKoJJpRSQQAAIAJlUQAAODyqCSakSQCAACQI5rQ3QwAAAATKokAAMDl0d1s5rSVxFOnTmnChAlWhwEAAOCSnDZJjIuL0/jx460OAwAAuACbzeawJaeyrLt57969/7r94MGD2RQJAAAA/smyJLFmzZqy2WwyDMO07cb6nJx9AwCAnIOUw8yyJLFgwYJ67bXX1KRJk5tu/+mnn9SmTZtsjgoAAACShUli7dq1deLECQUHB990+4ULF25aZQQAAMhq9F6aWZYkPvPMM7p06dItt5cuXVpz5szJxogAAICrIkc0syxJ7NChw79uDwgIUK9evbIpGgAAAPwdk2kDAACXR3ezmdPOkwgAAADrUEkEAAAuj0KiGZVEAAAAmFBJBAAALs/NjVLiP1leSVy1apU2bdpk/3nmzJmqWbOmunfvrvPnz1sYGQAAgOuyPEkcMmSIEhMTJUn79u3T4MGD1apVK8XGxioyMtLi6AAAgCuw2Ry35FSWdzfHxsYqNDRUkrRkyRJFRERo8uTJ2rlzp1q1amVxdAAAwBUwBY6Z5ZVELy8vXb58WZK0du1ahYeHS7r+bucbFUYAAABkL8uTxPr16ysyMlITJ07Utm3b1Lp1a0nSoUOHVLJkSYujs8ZnC+arZbOHdd+91dSjayft27vX6pBynZeeDNemT4bo9KbX9du6KC2c2kcVgovecv9lM/oradcMtWlUPd36RvdX1HdzI3V60+uKXTNZk55rJ3d3y/+3ynXeefst1a5eKd3SsW1Lq8NyadynnMOOH7fruQHPqFnj+qpZNUTr1621OqQci+5mM8t/m82YMUMeHh5avHixZs2apRIlSkiSVq5cqRYtWlgcXfZbtXKFXn8tSv2eHaDPFn2hkJBK6t/vKcXHx1sdWq7yUK3ymv35RjXs+boi+s+Qh4e7ls8aqLw+XqZ9B/VoLMMwn6NaxRJa9lZ/rd78sx7s9qoef/lDtW5YTZOea5cNn8D1lCtXQd+u/699+WDeAqtDclncp5xHUtJlVQwJ0fCRY60OBbmQ5WMSS5cureXLl5vWR0dHWxCN9T6eN0cdH+2s9h0ekSSNGjteGzd+r2VLl+ipPn0tji73aDfw7XQ/9x37iX5f/6ruDS2lH3Yeta+vXrGEnn/8YdXr8Zp+XRuV7phHw2tp/+ETinp3lSTp2O9nNfLNZfrkP0/qlXdW6OLlZMd/EBfi7uGuwoWLWB0GxH3KmdR/qKHqP9TQ6jByBcYkmlleSdy5c6f27dtn//nLL79U+/btNWLECKWkpFgYWfa7mpKiX37+SQ+G1bWvc3Nz04MP1tXePbssjCz3883vI0k6n3DZvi6Pj6fmRvXWC68u1Kn4v0zHeHt56Ery1XTrkpKvKo+Pl+6tXNqxAbug47/9puZNHlLblk018uWXdPLkCatDckncpwDXYXmS2K9fPx06dEiSdOzYMXXt2lV58+bVokWLNHTo0Nsen5ycrMTExHRLcnLOrOCcv3BeqampKlSoULr1hQoV0tmzZy2KKvez2Wya8tKj2rzrqH4+etK+/rXBj2jLnlgt/37fTY9bs/kXPVijrDq3qC03N5uCivhpRN/r4+SKF/HNlthdRdVqNTRuUpRmzHpfL48aqxN//qGnez+mS5cuWh2ay+E+hdzKZrM5bMmpLE8SDx06pJo1a0qSFi1apAYNGmjBggWaO3eulixZctvjo6Ki5Ofnl26Z8p+o2x4H3DBteGdVKV9cPV+eY1/XumE1Nbq/ooZMWXzL49ZtOaAR05Zp+oiuStg6TXu/HKNvN/0kSUpLu8kgRtyxeg81ULPwFqpQMUR16z2k6TPf1V9/JWrNt6usDg0Aci3LxyQahqG0tDRJ16fAiYiIkCSVKlUqQ3+VDh8+3DTptuHunfWBZoMA/wC5u7ubBn/Hx8ercOHCFkWVu0UP66RWD1VV06em6c/TF+zrG91XUWVLFlbcxinp9v/09af1w66jat7nTUnS9E/Wa/on61W8iJ/OJ15WcFBBTXyunWL/oKLiSAV8fRUcfI9+//03q0NxOdynkFvl4IKfw1ieJNapU0eTJk1S06ZNtWHDBs2aNUvS9Um2AwMDb3u8t7e3vL3TJ4VXrjkkVIfz9PJS5dAq2rolRg83aSpJSktL09atMera7TGLo8t9ood1UtuHayi8z5v67UT6X3ivz1mtOV9sTrdux+KRGvrGEn2zYb/pXCfPJEiSOreoo99PntOuA787LnDo8uVL+uP339Uqoq3Vobgc7lPIrXJyt7CjWJ4kTps2TT169NCyZcs0cuRIlS9fXpK0ePFi1a1b9zZH5z6P93pCo0cMU5UqVVW1WnV98vE8JSUlqX2HjlaHlqtMG95ZXVrWUacX39XFS1cUWKiAJCnh4hVdSb6qU/F/3fRhld9Pnk+XUL7Ys4lWb/5FaWlpatekpl56opkeG/oh3c1ZLPr1/6hBo8YqXjxIZ86c1jtvz5Cbu5tatIywOjSXxH3KeVy+fEnHjx+3//znn3/owIFf5Ofnp+LFgyyMDLmB5Uli9erV0z3dfMOUKVPk7u5uQUTWatGylc6fO6e3Z0zX2bNnFFKpst5+530VohsnS/Xr3ECStOb9F9Kt7zPmY33y9dYMnye8XqiGPt1c3p4e2nfoT3V68V2t/uHnrAwVkk6fPqURwwYr4cIFBQQUVM1atTX3k88VULCg1aG5JO5TzuOn/fvV58me9p/feO36mPw27Tpo4iuvWhVWjkQh0cxmGDebJjhny6ndzblRwH0DrQ4Bf3Nmy1tWh4D/8XDnN5KzyH2/BXOuPJ7WXbvWhPUOO/fOMQ877NyOZHklMTU1VdHR0Vq4cKGOHz9umhvx3LlzFkUGAABcBWMSzSyfAmf8+PGaOnWqunTpooSEBEVGRqpjx45yc3PTuHHjrA4PAADAJVmeJM6fP1/vvfeeBg8eLA8PD3Xr1k3vv/++xowZoy1btlgdHgAAcAE2m+OWnMryJDEuLk7VqlWTJOXPn18JCdenEomIiNA333xjZWgAAAAuy/IksWTJkjp58vqr0MqVK6fVq1dLkrZv326a/xAAAMAReC2fmeVJYocOHbRu3TpJ0qBBgzR69GhVqFBBPXv21JNPPmlxdAAAAK7J8qebX331/+dx6tKli0qXLq2YmBhVqFBBbdq0sTAyAADgKnJwwc9hLE8S/yksLExhYWFWhwEAAFxITu4WdhRLksSvvvoqw/u2bcu7WQEAALKbJUli+/btM7SfzWZTamqqY4MBAAAuj0KimSVJYlpamhWXBQAAQAY53ZhEAACA7MaYRDPLpsBZv369QkNDlZiYaNqWkJCgKlWqaOPGjRZEBgAAAMuSxGnTpqlPnz7y9fU1bfPz81O/fv0UHR1tQWQAAMDV8Fo+M8uSxD179qhFixa33B4eHq4dO3ZkY0QAAAC4wbIxiadOnZKnp+ctt3t4eOjMmTPZGBEAAHBVjEk0s6ySWKJECe3fv/+W2/fu3avixYtnY0QAAMBV0d1sZlmS2KpVK40ePVpXrlwxbUtKStLYsWMVERFhQWQAAACwrLt51KhRWrp0qSpWrKiBAwcqJCREknTgwAHNnDlTqampGjlypFXhAQAAF0J3s5llSWJgYKA2b96s/v37a/jw4TIMQ9L1RmrevLlmzpypwMBAq8IDAABwaZZOph0cHKwVK1bo/PnzOnLkiAzDUIUKFRQQEGBlWAAAwMVQSTRzijeuBAQE6L777rM6DAAAAPyPUySJAAAAVqKQaGbZ080AAABwXlQSAQCAy2NMohlJIgAAcHnkiGZ0NwMAAMCESiIAAHB5dDebUUkEAACACZVEAADg8igkmlFJBAAAgAmVRAAA4PLcKCWaUEkEAACACZVEAADg8igkmpEkAgAAl8cUOGZ0NwMAAMCEJBEAALg8N5vjlszauHGj2rRpo6CgINlsNi1btizd9t69e8tms6VbWrRokW6fc+fOqUePHvL19ZW/v7+eeuopXbx4MXPfSeZDBwAAgKNcunRJNWrU0MyZM2+5T4sWLXTy5En78umnn6bb3qNHD/30009as2aNli9fro0bN6pv376ZioMxiQAAwOU5ckxicnKykpOT063z9vaWt7f3Tfdv2bKlWrZs+a/n9Pb2VrFixW667ZdfftGqVau0fft21alTR5L01ltvqVWrVnr99dcVFBSUobipJAIAADhQVFSU/Pz80i1RUVF3dc7vv/9eRYsWVUhIiPr376/4+Hj7tpiYGPn7+9sTRElq2rSp3NzctHXr1gxfg0oiAABweY58uHn48OGKjIxMt+5WVcSMaNGihTp27KgyZcro6NGjGjFihFq2bKmYmBi5u7srLi5ORYsWTXeMh4eHChYsqLi4uAxfhyQRjpXXz+oI8Ddu9B0AJsx8Akf7t67lO9G1a1f7v1erVk3Vq1dXuXLl9P3336tJkyZZdh1+ZQAAAJdnc+A/jla2bFkVLlxYR44ckSQVK1ZMp0+fTrfPtWvXdO7cuVuOY7wZkkQAAODynGkKnMz6448/FB8fr+LFi0uSwsLCdOHCBe3YscO+z/r165WWlqYHHnggw+eluxkAAMCJXLx40V4VlKTY2Fjt3r1bBQsWVMGCBTV+/Hg98sgjKlasmI4ePaqhQ4eqfPnyat68uSSpcuXKatGihfr06aPZs2fr6tWrGjhwoLp27ZrhJ5slkkQAAACnei3fjz/+qMaNG9t/vvHQS69evTRr1izt3btX8+bN04ULFxQUFKTw8HBNnDgx3bjH+fPna+DAgWrSpInc3Nz0yCOPaPr06ZmKgyQRAADAiTRq1EiGYdxy+7fffnvbcxQsWFALFiy4qzhIEgEAgMtzokKi0+DBFQAAAJhQSQQAAC7PjVKiCZVEAAAAmFBJBAAALo9CohlJIgAAcHnONAWOs6C7GQAAACZUEgEAgMujkGhGJREAAAAmVBIBAIDLYwocMyqJAAAAMKGSCAAAXB51RDMqiQAAADChkggAAFwe8ySakSQCAACX50aOaEJ3MwAAAEyoJAIAAJdHd7OZ5ZXEP/74QxcvXjStv3r1qjZu3GhBRAAAALAsSTx58qTuv/9+BQcHy9/fXz179kyXLJ47d06NGze2KjwAAOBCbDbHLTmVZUniyy+/LDc3N23dulWrVq3Szz//rMaNG+v8+fP2fQzDsCo8AAAAl2bZmMS1a9fqiy++UJ06dSRJP/zwgzp16qSHH35Y69atk8T4AAAAkD3IOcwsqyQmJCQoICDA/rO3t7eWLl2qe+65R40bN9bp06etCg0AAMDlWZYkli1bVnv37k23zsPDQ4sWLVLZsmUVERFhUWQAAMDVuNkct+RUliWJLVu21LvvvmtafyNRrFmzZvYHBQAAXJLNZnPYklNZNibxlVde0eXLl2+6zcPDQ0uWLNGff/6ZzVEBAABAsjBJ9PDwkK+v779uDw4OzsaIAACAq8q59T7HsXwybQAAADifO0oS//vf/+qxxx5TWFiYvUv4448/1qZNm7I0OAAAgOzgZrM5bMmpMp0kLlmyRM2bN1eePHm0a9cuJScnS7o+pc3kyZOzPEAAAABkv0wniZMmTdLs2bP13nvvydPT076+Xr162rlzZ5YGBwAAkB14LZ9ZppPEgwcPqkGDBqb1fn5+unDhQqYDWLVqVbpu6pkzZ6pmzZrq3r17ulf0AQAAIPtkOkksVqyYjhw5Ylq/adMmlS1bNtMBDBkyRImJiZKkffv2afDgwWrVqpViY2MVGRmZ6fMBAABkFvMkmmV6Cpw+ffro+eef14cffiibzaYTJ04oJiZGL730kkaPHp3pAGJjYxUaGirp+njHiIgITZ48WTt37lSrVq0yfT4AAADcvUwniS+//LLS0tLUpEkTXb58WQ0aNJC3t7deeuklDRo0KNMBeHl52SfVXrt2rXr27ClJKliwoL3CCAAA4Eg5uODnMJlOEm02m0aOHKkhQ4boyJEjunjxokJDQ5U/f/47CqB+/fqKjIxUvXr1tG3bNn3++eeSpEOHDqlkyZJ3dM6c7rMF8zVvzgc6e/aMKoZU0ssjRqta9epWh5WrvPR4A7VvWEUVg4soKfmqtu47rpGzvtXh42ft+7w1pJ0evq+cihf21cXLKdqy/7hGvb1Kh/62T6PaZTW2T1NVKVdMl5JSNH/lLo19d41SU9Os+Fi51gfvvaP1a9fo19hj8vbxUY2a9+r5FwfrnjKZH+KCrMF9ynnQFlkjJ09V4yh3PJm2l5eXQkNDdf/9999xgihJM2bMkIeHhxYvXqxZs2apRIkSkqSVK1eqRYsWd3zenGrVyhV6/bUo9Xt2gD5b9IVCQiqpf7+nFB8fb3VoucpDNcto9tItath3tiJemCMPD3ctj+6tvD7//8T+roMn1PeVparZfZraRs6VzSYtj35Cbv97W3u18sW07PVeWr31sB7sPUOPj/lMretX0qRnwq36WLnWzh+3q0u37vpoweea9e6Hunb1mvr3fVpJt3i1JxyL+5TzoC3gSDbDMIzMHNC4ceN/HYS5fv36uw7qbl25ZnUEd65H106qUrWaRowaI0lKS0tTeJOG6tb9cT3Vp6/F0WVeQMORVoeQIYX98+r3b0aq6bPv6Yc9v950n6rlArX9o+cU2vkNxf55TuP7NVOT+8qr/tOz7Pu0qldJn0zsqtIRk3Xxcko2RZ9x8d9PsjqELHHu3Dk1aVBX78/9WLXr3Gd1OHckJ1ctctt9KifLbW3hY9nLgqVnl/7ssHO/3THUYed2pExXEmvWrKkaNWrYl9DQUKWkpGjnzp2qVq1apgPYuXOn9u3bZ//5yy+/VPv27TVixAilpDjfL1lHupqSol9+/kkPhtW1r3Nzc9ODD9bV3j27LIws9/PN5yNJOp9488pUXh9P9WxdW7F/ntMfpxIkSd6eHrqSkv4vkqTkq8rj7al7Q0o4NmAXd/HiX5KuT72F7MV9ynnQFnC0TOfs0dHRN10/btw4Xbx4MdMB9OvXTy+//LKqVaumY8eOqWvXrurQoYMWLVqky5cva9q0aZk+Z051/sJ5paamqlChQunWFypUSLGxxyyKKvez2Wya8nxrbd7zq36OPZ1uW98OD+iVZ5srf15vHfztjFq/OEdXr6VKktZsO6yBneuqc9PqWrx+n4oVLKARTzSWJBUvVCDbP4erSEtL0+uvTlbNe2upfIWKVofjcrhPOQ/aImvl5KlqHOWOxyT+02OPPaYPP/ww08cdOnRINWvWlCQtWrRIDRo00IIFCzR37lwtWbLktscnJycrMTEx3XLjVYFARkwb3EZVygaq59jPTds+W71bDz4xU02ffU+Hfz+rTyZ0lbfX9b+t1m07ohEzV2n6kHZK+G689n72or6NOSRJSsvcKA5kQtSkCTpy5LBenTLV6lAAIFfLsiQxJiZGPj4+mT7OMAylpV1/EnTt2rX2uRFLlSqls2fP/tuhkqSoqCj5+fmlW6b8JyrTcTiDAP8Aubu7mwYcx8fHq3DhwhZFlbtFR7ZRq7ohaj7oA/15xjzlUuKlZB39I14/7PlV3Ud+qpDgImrX4P/Hlkz//AcVaz5RFR+ZopKtXtHX//1FkhT757ls+wyu5NVXJui/G77Xex9+pMBixawOxyVxn3IetEXWcnPgklNluru5Y8eO6X42DEMnT57Ujz/+eEeTadepU0eTJk1S06ZNtWHDBs2adf0hgNjYWAUGBt72+OHDh5vezGK4e2c6Dmfg6eWlyqFVtHVLjB5u0lTS9a61rVtj1LXbYxZHl/tER7ZR2wahCh/4vn47eftXQN54B6eXl7tp28mz18fIdW5WXb/HXdCuQyeyPF5XZhiG/jN5otavW6v35nykEi46PZYz4D7lPGgLOFqmk8R/DhR3c3NTSEiIJkyYoPDwzE/9MW3aNPXo0UPLli3TyJEjVb58eUnS4sWLVbdu3dscLXl7e8vbO31SmJOfbn681xMaPWKYqlSpqqrVquuTj+cpKSlJ7Tt0vP3ByLBpg9uqS7Pq6vTyJ7p4OVmBBa9P45Rw8YqupFzTPUEBerRJNa3bdkRnL1xSiSJ+Gvx4AyUlX9O3mw/Zz/Ni9/paveWw0gxD7RpW0UuPNdBjoz9TWhrdzVkpatIErVyxXNHTZypfvnw6e/aMJCl//gJ31IOBu8N9ynnQFlmHMYlmmZoCJzU1VT/88IOqVaumgIAAR8alK1euyN3dXZ6enrff+Z/H5uAkUZI+nf+JfWLUkEqVNWzEKFWvXsPqsO6Is06Bk/TDKzdd3+eVxfpkxS4VL1xAb7/cQfeGlFBAAR+dPndRm/b8qslzvks34fbK6U+qZsUgeXt5aN+Rk3rlw++0esuhm57bGeTUKXDurVrppuvHT5qstu1z5i/DnDwFjpS77lM5XW5qCyunwHnhywMOO/e0dje/hzm7TM+T6OPjo19++UVlypRxVEx3LacnibmJsyaJriqnJom5UU5PEgFHIEl0LplujqpVq+rYsWNZliSmpqYqOjpaCxcu1PHjx01zI547xwMAAADAsdz4u80k0w/dTJo0SS+99JKWL1+ukydPmqafyazx48dr6tSp6tKlixISEhQZGamOHTvKzc1N48aNy/T5AAAAcPcyXEmcMGGCBg8ebJ+ipm3btukGeRqGIZvNptTU1EwFMH/+fL333ntq3bq1xo0bp27duqlcuXKqXr26tmzZoueeey5T5wMAAMgsHlwxy3CSOH78eD3zzDP67rvvsjSAuLg4++v88ufPr4SE6688i4iIuKMpdQAAAHD3Mpwk3ni+pWHDhlkaQMmSJXXy5EmVLl1a5cqV0+rVq1WrVi1t377dNLUNAACAIzAm0SxTYxIdUYrt0KGD1q1bJ0kaNGiQRo8erQoVKqhnz5568skns/x6AAAAuL1MPd1csWLF2yaKmX0a+dVXX7X/e5cuXVS6dGnFxMSoQoUKatOmTabOBQAAcCcYkmiWqSRx/PjxpjeuZLWwsDCFhYU59BoAAAB/x9ylZplKErt27aqiRYve9UW/+uqrDO/btm3bu74eAAAAMifDSWJWjkds3759hq+Z2Sl1AAAAMivTE0e7gEw/3ZwV0tLSsuxcAAAAyHoZThJJ7AAAQG7FkEQzy6qr69evV2ho6E1f5ZeQkKAqVapo48aNFkQGAAAAy5LEadOmqU+fPvL19TVt8/PzU79+/RQdHW1BZAAAwNW42WwOW3Iqy5LEPXv2qEWLFrfcHh4erh07dmRjRAAAALghU1PgZKVTp07J09Pzlts9PDx05syZbIwIAAC4qhxc8HMYyyqJJUqU0P79+2+5fe/evSpevHg2RgQAAFyVm81xS05lWZLYqlUrjR49WleuXDFtS0pK0tixYxUREWFBZAAAALCsu3nUqFFaunSpKlasqIEDByokJESSdODAAc2cOVOpqakaOXKkVeEBAAAXkpMfMHEUy5LEwMBAbd68Wf3799fw4cPtk3XbbDY1b95cM2fOVGBgoFXhAQAAuDTLkkRJCg4O1ooVK3T+/HkdOXJEhmGoQoUKCggIsDIsAADgYigkmlmaJN4QEBCg++67z+owAAAA8D9OkSQCAABYKSc/hewolj3dDAAAAOdFJREAALg8mygl/hNJIgAAcHl0N5vR3QwAAAATKokAAMDlUUk0o5IIAAAAEyqJAADA5dmYTduESiIAAABMqCQCAACXx5hEMyqJAAAAMKGSCAAAXB5DEs1IEgEAgMtzI0s0obsZAAAAJiSJAADA5bnZHLdk1saNG9WmTRsFBQXJZrNp2bJl6bYbhqExY8aoePHiypMnj5o2barDhw+n2+fcuXPq0aOHfH195e/vr6eeekoXL17M3HeS+dABAADgKJcuXVKNGjU0c+bMm25/7bXXNH36dM2ePVtbt25Vvnz51Lx5c125csW+T48ePfTTTz9pzZo1Wr58uTZu3Ki+fftmKg7GJAIAAJfnTEMSW7ZsqZYtW950m2EYmjZtmkaNGqV27dpJkj766CMFBgZq2bJl6tq1q3755RetWrVK27dvV506dSRJb731llq1aqXXX39dQUFBGYqDSiIAAIADJScnKzExMd2SnJx8R+eKjY1VXFycmjZtal/n5+enBx54QDExMZKkmJgY+fv72xNESWratKnc3Ny0devWDF+LJBEAALg8N9kctkRFRcnPzy/dEhUVdUdxxsXFSZICAwPTrQ8MDLRvi4uLU9GiRdNt9/DwUMGCBe37ZATdzXCspL+sjgB/Z1gdAOycqGsLgGMNHz5ckZGR6dZ5e3tbFE3GkSQCAACX58gxid7e3lmWFBYrVkySdOrUKRUvXty+/tSpU6pZs6Z9n9OnT6c77tq1azp37pz9+IyguxkAALg8Z5oC59+UKVNGxYoV07p16+zrEhMTtXXrVoWFhUmSwsLCdOHCBe3YscO+z/r165WWlqYHHnggw9eikggAAOBELl68qCNHjth/jo2N1e7du1WwYEGVLl1aL7zwgiZNmqQKFSqoTJkyGj16tIKCgtS+fXtJUuXKldWiRQv16dNHs2fP1tWrVzVw4EB17do1w082SySJAAAATvVavh9//FGNGze2/3xjPGOvXr00d+5cDR06VJcuXVLfvn114cIF1a9fX6tWrZKPj4/9mPnz52vgwIFq0qSJ3Nzc9Mgjj2j69OmZisNmGEauG8p+5ZrVEeCGgPufszoE/E38ljetDgH/45bVfVBALuBjYenq3S2/OezcfR8Mdti5HYlKIgAAcHlOVEh0Gjy4AgAAABMqiQAAwOU505hEZ0ElEQAAACZUEgEAgMujkGhGkggAAFweXatmfCcAAAAwoZIIAABcno3+ZhMqiQAAADChkggAAFwedUQzKokAAAAwoZIIAABcHpNpm1FJBAAAgAmVRAAA4PKoI5qRJAIAAJdHb7MZ3c0AAAAwoZIIAABcHpNpm1FJBAAAgImllcT4+Hjt3btXNWrUUMGCBXX27Fl98MEHSk5OVqdOnVS5cmUrwwMAAC6CqpmZZUnitm3bFB4ersTERPn7+2vNmjXq1KmTPDw8lJaWpldffVWbNm1SrVq1rAoRAADAZVmWOI8cOVKdOnVSQkKCRowYofbt26tJkyY6dOiQjhw5oq5du2rixIlWhQcAAFyIzWZz2JJTWZYk7tixQ5GRkSpQoICef/55nThxQn369LFvHzhwoLZv325VeAAAAC7Nsu7mlJQU5cmTR5Lk6empvHnzqnDhwvbthQsXVnx8vFXhAQAAF5Jz632OY1klsVSpUjp27Jj9588++0zFixe3/3zy5Ml0SSMAAACyj2WVxK5du+r06dP2n1u3bp1u+1dffaX7778/u8MCAAAuKCePHXQUy5LEsWPH/uv2kSNHyt3dPZuiAQAArowpcMyc9o0refPmtToEAAAAl+W0SSIAAEB2obvZjOoqAAAATKgkAgAAl0cd0YxKIgAAAEwsTxJXrVqlTZs22X+eOXOmatasqe7du+v8+fMWRgYAAFyFzea4JaeyPEkcMmSIEhMTJUn79u3T4MGD1apVK8XGxioyMtLi6AAAAFyT5WMSY2NjFRoaKklasmSJIiIiNHnyZO3cuVOtWrWyODoAAOAK3BiVaGJ5JdHLy0uXL1+WJK1du1bh4eGSpIIFC9orjAAAAI5Ed7OZ5Uli/fr1FRkZqYkTJ2rbtm321/MdOnRIJUuWtDg6a3y2YL5aNntY991bTT26dtK+vXutDinXeemJZtr08WCd/u9r+m3tK1r4xtOqEFz0lvsve+sZJe2crjaNqqVbXzu0tFbMHqCTG17Vie9f1Vcz+6tahSBHh+9yFn7+qTp3bKv6D9ZW/Qdrq2ePLtr0341Wh+XSuE85D9oCjmJ5kjhjxgx5eHho8eLFmjVrlkqUKCFJWrlypVq0aGFxdNlv1coVev21KPV7doA+W/SFQkIqqX+/pxQfH291aLnKQ7XLa/bC/6phr6mK6D9THh7uWv72s8rr42Xad1CPRjIMw7Q+Xx4vfTmjv36PO68GPaeqyZPTdPFSsr6a+aw8PCz/XytXCQwM1KAXBmv+50s0/7PFuv+BB/XicwN09Mhhq0NzSdynnAdtkXVsDvwnp7IZN/vtl8NduWZ1BHeuR9dOqlK1mkaMGiNJSktLU3iThurW/XE91aevxdFlXsD9z1kdQoYU9s+v39dPVtOn39QPO4/a11evWEJL3+yneo9N0a9rXlHnyPf09ff7JEm1KpfSD/OHqELLMfrj1AVJUpXyxfXjwuGq0m6Cjv1+1oqP8q/it7xpdQhZpmG9B/TC4CHq0PFRq0O5I25uOfcXR267T+Vkua0tfCx8UuKb/acddu7WVW/dU+XMLC937Ny5U/v27bP//OWXX6p9+/YaMWKEUlJSLIws+11NSdEvP/+kB8Pq2te5ubnpwQfrau+eXRZGlvv5FvCRJJ1PuGxfl8fHU3Mn99ILry7Sqfi/TMcc+u20zp6/qF7tw+Tp4S4fb0/1bh+mX47F6bcT57ItdleTmpqqVSu/UVLSZVWvUdPqcFwO9ynnQVtkLcYkmlmeJPbr10+HDh2SJB07dkxdu3ZV3rx5tWjRIg0dOvS2xycnJysxMTHdkpyc7OiwHeL8hfNKTU1VoUKF0q0vVKiQzp51vqpUbmGz2TTlpY7avOuofj560r7+tcEdtWVPrJZv2HfT4y5eTlbzvm+pW6s6Oh/zhs5umqJmYZXVftAspaamZVf4LuPwoYOqe38tPVC7ul6ZOE5vTJuhcuXKWx2Wy+E+5TxoCzia5UnioUOHVLNmTUnSokWL1KBBAy1YsEBz587VkiVLbnt8VFSU/Pz80i1T/hPl4KiRm0x7uZOqlCuunsPn2de1blBVje6roCGv3/q/QR9vT80e000xu4+pYa+pevjJafr56EktfbOffLw9syN0l3JPmTL6bPEX+mj+5+rUuavGjHpZR48esTosALmEm2wOW3Iqy+dJNAxDaWnXqy5r165VRESEJKlUqVIZ+kto+PDhpkm3DXfvrA80GwT4B8jd3d004Dg+Pl6FCxe2KKrcLXrYo2r1UBU1ffpN/Xn6gn19o/srqmzJworb8J90+3865Sn9sOuomvd9S11a1FbpoIJq2Dva/mBLrxHzdHLDq2rTsJoWrd6ZnR8l1/P09FLp0sGSpNAqVfXT/v369JOPNGrsBIsjcy3cp5wHbQFHs7ySWKdOHU2aNEkff/yxNmzYYJ8CJzY2VoGBgbc93tvbW76+vukWb++cmSR6enmpcmgVbd0SY1+XlpamrVtjVL3GvRZGljtFD3tUbRtXV4t+M0xjCF+fs0b3dfmPHuj2mn2RpKFvLFXfcfMlSXl9vJSWZqR78jnNMGQYOfuhhJzCMNJcbtyyM+A+5Txoi6zFmEQzyyuJ06ZNU48ePbRs2TKNHDlS5ctfH2O0ePFi1a1b9zZH5z6P93pCo0cMU5UqVVW1WnV98vE8JSUlqX2HjlaHlqtMe7mTurSsrU4vvq+Ll68osFABSVLCxSu6knxVp+L/uunDKr/HnbcnlOu2HtDkF9pp2sudNOvzjXKz2fTSE810LTVVG35kapasNH3aG6pXv4GKFy+uS5cuaeWK5fpx+za9Pft9q0NzSdynnAdtkXVycjLnKJYnidWrV0/3dPMNU6ZMkbu7uwURWatFy1Y6f+6c3p4xXWfPnlFIpcp6+533VYiugyzVr/NDkqQ176efoqfP2E/0ydfbMnSOQ7+e1iMvvKuRfVvo+7kvKi3N0J6Df6jdwNmKO8vbgrLSuXPnNHrkMJ09c0b5CxRQhQohenv2+3qwbj2rQ3NJ3KecB20BR2KeRDhUTpkn0VXkpnkSczqGJABmVs6TuOYXxz0R3qxyzkzaLa8kpqamKjo6WgsXLtTx48dNY4zOnWO+OQAAgOxm+YMr48eP19SpU9WlSxclJCQoMjJSHTt2lJubm8aNG2d1eAAAwAW42Ry35FSWJ4nz58/Xe++9p8GDB8vDw0PdunXT+++/rzFjxmjLli1WhwcAAOCSLE8S4+LiVK1aNUlS/vz5lZCQIEmKiIjQN998Y2VoAADARdgc+E9OZXmSWLJkSZ08ef1VaOXKldPq1aslSdu3b8+x8x0CAADkdJYniR06dNC6deskSYMGDdLo0aNVoUIF9ezZU08++aTF0QEAAFfAZNpmlj/d/Oqrr9r/vUuXLipdurRiYmJUoUIFtWnTxsLIAACAq8jJ3cKOYnmS+E9hYWEKCwuzOgwAAACXZkmS+NVXX2V437Zt2zowEgAAgJw9VY2jWJIktm/fPkP72Ww2paamOjYYAAAAmFiSJKalpVlxWQAAgJtiTKKZ5U83AwAAwPlYliSuX79eoaGhSkxMNG1LSEhQlSpVtHHjRgsiAwAAroYpcMwsSxKnTZumPn36yNfX17TNz89P/fr1U3R0tAWRAQAAwLIkcc+ePWrRosUtt4eHh2vHjh3ZGBEAAHBVNgcuOZVl8ySeOnVKnp6et9zu4eGhM2fOZGNEAADAVbnl5H5hB7GskliiRAnt37//ltv37t2r4sWLZ2NEAAAAuMGyJLFVq1YaPXq0rly5YtqWlJSksWPHKiIiwoLIAACAq6G72cxmGIZhxYVPnTqlWrVqyd3dXQMHDlRISIgk6cCBA5o5c6ZSU1O1c+dOBQYGZvrcV65ldbS4UwH3P2d1CPib+C1vWh0C/seN1zsAJj4Wvix4y5ELDjv3g+X9HXZuR7KsOQIDA7V582b1799fw4cP141c1WazqXnz5po5c+YdJYgAAACZxt9tJhbm7FJwcLBWrFih8+fP68iRIzIMQxUqVFBAQICVYQEAALg8S5PEGwICAnTfffdZHQYAAHBRvJbPjNfyAQAAwMQpKokAAABWYppEM5JEAADg8sgRzehuBgAAgAmVRAAAAEqJJlQSAQAAYEIlEQAAuDymwDGjkggAAAATKokAAMDlMQWOGZVEAAAAmFBJBAAALo9CohlJIgAAAFmiCd3NAAAAMKGSCAAAXB5T4JhRSQQAAHAS48aNk81mS7dUqlTJvv3KlSsaMGCAChUqpPz58+uRRx7RqVOnHBILSSIAAHB5NpvjlsyqUqWKTp48aV82bdpk3/biiy/q66+/1qJFi7RhwwadOHFCHTt2zMJv4v/R3QwAAOBEPDw8VKxYMdP6hIQEffDBB1qwYIEefvhhSdKcOXNUuXJlbdmyRQ8++GCWxkElEQAAuDybA5fk5GQlJiamW5KTk28Zy+HDhxUUFKSyZcuqR48eOn78uCRpx44dunr1qpo2bWrft1KlSipdurRiYmKy7sv4HyqJcCz/QKsjwN8xLhsAsl1UVJTGjx+fbt3YsWM1btw4074PPPCA5s6dq5CQEJ08eVLjx4/XQw89pP379ysuLk5eXl7y9/dPd0xgYKDi4uKyPG6SRAAAAAf+ET18+HBFRkamW+ft7X3TfVu2bGn/9+rVq+uBBx5QcHCwFi5cqDx58jguyJsgSQQAAC7PkVPgeHt73zIpvB1/f39VrFhRR44cUbNmzZSSkqILFy6kqyaeOnXqpmMY7xZjEgEAAJzUxYsXdfToURUvXly1a9eWp6en1q1bZ99+8OBBHT9+XGFhYVl+bSqJAADA5d3JVDWO8NJLL6lNmzYKDg7WiRMnNHbsWLm7u6tbt27y8/PTU089pcjISBUsWFC+vr4aNGiQwsLCsvzJZokkEQAAwGn88ccf6tatm+Lj41WkSBHVr19fW7ZsUZEiRSRJ0dHRcnNz0yOPPKLk5GQ1b95cb7/9tkNisRmGYTjkzBa6cs3qCHBDQPgrVoeAv4n/doTVIeB/3JylbAE4ER8LS1f7/7josHNXLZnfYed2JMYkAgAAwITuZgAAAIr7JlQSAQAAYEIlEQAAuDxHzpOYU1FJBAAAgAmVRAAA4PKYcMCMJBEAALg8ckQzupsBAABgQiURAACAUqIJlUQAAACYUEkEAAAujylwzKgkAgAAwIRKIgAAcHlMgWNGJREAAAAmVBIBAIDLo5BoRpIIAABAlmhCdzMAAABMnC5JLFu2rA4fPmx1GAAAwIXYHPhPTmVZd/P06dNvuv748eOaM2eOihUrJkl67rnnsjMsAAAASLIZhmFYcWE3NzeVKFFCHh7p89TffvtNQUFB8vT0lM1m07FjxzJ97ivXsipK3K2A8FesDgF/E//tCKtDwP+4Md8GYOJj4ZMSR04nOezc5Yvmcdi5Hcmy5ujbt6+2bt2qBQsWqHLlyvb1np6eWr16tUJDQ60KDQAAwOVZNiZx9uzZGjNmjJo3b64ZM2ZYFQYAAIBsDlxyKksfXOnQoYNiYmL0xRdfqGXLloqLi7MyHAAAAPyP5U83lyhRQmvXrlWDBg107733yqIhkgAAwJVRSjRxism0bTabhg8frvDwcG3atEnFixe3OiQAAOBCcvJUNY7iFEniDbVr11bt2rWtDgMAAMDlOVWSCAAAYAVmpTKzfEwiAAAAnA+VRAAA4PIoJJpRSQQAAICJ5UniqlWrtGnTJvvPM2fOVM2aNdW9e3edP3/ewsgAAIDLYAocE8uTxCFDhigxMVGStG/fPg0ePFitWrVSbGysIiMjLY4OAADANVk+JjE2Ntb+nuYlS5YoIiJCkydP1s6dO9WqVSuLowMAAK6AeRLNLK8kenl56fLly5KktWvXKjw8XJJUsGBBe4URAADAkWw2xy05leWVxPr16ysyMlL16tXTtm3b9Pnnn0uSDh06pJIlS1ocnTU+WzBf8+Z8oLNnz6hiSCW9PGK0qlWvbnVYucpL3eqq/UMhqli6kJKSr2nrT39o5Hvrdfj3c/Z93nqxpR6uXUbFC+XXxaQUbfnpT416d70O/R4vSSrom0dzRrRTtbJFVdA3j85cuKzlmw9pzPvf6a/LKVZ9tFzpg/fe0fq1a/Rr7DF5+/ioRs179fyLg3VPmbJWh+ayuE85D9oCjmJ5JXHGjBny8PDQ4sWLNWvWLJUoUUKStHLlSrVo0cLi6LLfqpUr9PprUer37AB9tugLhYRUUv9+Tyk+Pt7q0HKVh2qU1uwvd6jhwLmKGLJAHh7uWv5ad+X18bTvs+tQnPq+9rVq9n5HbYd9JptNWv5aN7m5Xf+zMC3N0PLNh/ToqEWq3muW+vznazWudY/eerGlVR8r19r543Z16dZdHy34XLPe/VDXrl5T/75PK+l/vRDIXtynnAdtkXV4bsXMZhiGYXUQWe3KNasjuHM9unZSlarVNGLUGElSWlqawps0VLfuj+upPn0tji7zAsJfsTqEDCnsl1e/f/Gimr7wkX7Y+/tN96latqi2v99HoY/NVOyJCzfd59kOdfRilzBV6PqWA6O9c/HfjrA6hCxx7tw5NWlQV+/P/Vi169xndTh3xC0H90HltvtUTpbb2sLHwv7N388lO+zcpQp6O+zcjmR5JXHnzp3at2+f/ecvv/xS7du314gRI5SS4lpddldTUvTLzz/pwbC69nVubm568MG62rtnl4WR5X6++a7/D3w+8cpNt+f18VTPFtUVe+K8/jh987GyxQvlV7uHKum/e35zWJy47uLFvyRJfn5+FkfierhPOQ/aImsxJtHM8iSxX79+OnTokCTp2LFj6tq1q/LmzatFixZp6NChFkeXvc5fOK/U1FQVKlQo3fpChQrp7NmzFkWV+9ls0pQBzbR53+/6+dcz6bb1bVtbZ74ZovgVQxV+fzm1HrpAV6+lpdtn3qj2il8xVMcWPa/Ey8nq//o32Rm+y0lLS9Prr05WzXtrqXyFilaH43K4TzkP2gKOZnmSeOjQIdWsWVOStGjRIjVo0EALFizQ3LlztWTJktsen5ycrMTExHRLcrLjSsbIfaY930JVyhRRz4lfmLZ9tm6/Huz7vpq+8JEO/3FOn4zpKG9P93T7DJ25RmH9PtCjoxaqbFCA/vNss+wK3SVFTZqgI0cO69UpU60OBUCuwqjEf7I8STQMQ2lp1ysza9eutc+NWKpUqQz9JRQVFSU/P790y5T/RDk0ZkcJ8A+Qu7u7acBxfHy8ChcubFFUuVv0c83V6sEKah75if48+5dpe+KlZB3987x+2Pu7uo9bopBShdTuoZB0+5w6f0mHfo/XN5sPa9DUFerXrraKFcyfXR/Bpbz6ygT9d8P3eu/DjxRYrJjV4bgk7lPOg7aAo1meJNapU0eTJk3Sxx9/rA0bNqh169aSrk+yHRgYeNvjhw8froSEhHTLkGHDHR22Q3h6ealyaBVt3RJjX5eWlqatW2NUvca9FkaWO0U/11xt64eoxeBP9Ftcwm33t9lsstls8vK89chq2/+efPb6R7URd8cwDL36ygStX7dW73w4VyVcdHosZ8B9ynnQFlmLMYlmls+TOG3aNPXo0UPLli3TyJEjVb58eUnS4sWLVbdu3dscLXl7e8vbO/1TQzn56ebHez2h0SOGqUqVqqparbo++XiekpKS1L5DR6tDy1WmPd9CXZpUUadRi3TxcooCA/JJkhIuJetKyjXdU9xfjzYK1bofj+lswmWVKFJAg7vVVVLyVX279YgkqfkD5VQ0IJ92HDipi0kpCr2niCb3e1ib9/2u46dun3Qi46ImTdDKFcsVPX2m8uXLp7Nnr48dzZ+/gHx8fCyOzvVwn3IetEXWycG5nMM47RQ4V65ckbu7uzw9PW+/8z+PzcFJoiR9Ov8T+8SoIZUqa9iIUapevYbVYd0RZ50CJ2n9yJuu7/Ofr/XJt3tVvFB+vf1Sa91boZgCCuTR6fOXtGnvcU3++L/2Cbcb1AzW+KcaqVJwYXl7uuuP04n6ctNBvb5gsxIuOee42Jw6Bc69VSvddP34SZPVtn3O/GWYk6fAkXLXfSqny01tYeUUOCcuOG5GlSB/L4ed25GcNkm8Gzk9ScxNnDVJdFU5NUnMjXJ6kgg4gpVJ4skExyWJxf1yZpJoeXdzamqqoqOjtXDhQh0/ftw0N+K5c+ducSQAAAAcxfIHV8aPH6+pU6eqS5cuSkhIUGRkpDp27Cg3NzeNGzfO6vAAAIALsDnwn5zK8iRx/vz5eu+99zR48GB5eHioW7duev/99zVmzBht2bLF6vAAAABckuVJYlxcnKpVqyZJyp8/vxISrj8VGhERoW++4c0VAAAgGzCXtonlSWLJkiV18uRJSVK5cuW0evVqSdL27dtNU9sAAAAge1ieJHbo0EHr1q2TJA0aNEijR49WhQoV1LNnTz355JMWRwcAAFwBhUQzp5sCJyYmRjExMapQoYLatGlzR+dgChznwRQ4zoUpcJwHU+AAZlZOgXP6r6sOO3fRApmf89kZWD4Fzj+FhYUpLCzM6jAAAABcmiVJ4ldffZXhfdu2bevASAAAAJSjp6pxFEuSxPbt22doP5vNptTUVMcGAwAAABNLksS0tDQrLgsAAHBzFBJNLH+6GQAAAM7HsiRx/fr1Cg0NVWJiomlbQkKCqlSpoo0bN1oQGQAAcDVMgWNmWZI4bdo09enTR76+vqZtfn5+6tevn6Kjoy2IDAAAAJYliXv27FGLFi1uuT08PFw7duzIxogAAICrstkct+RUls2TeOrUKXl63npySQ8PD505cyYbIwIAAK6KKXDMLKsklihRQvv377/l9r1796p48eLZGBEAAABusCxJbNWqlUaPHq0rV66YtiUlJWns2LGKiIiwIDIAAOBq6G42s+zdzadOnVKtWrXk7u6ugQMHKiQkRJJ04MABzZw5U6mpqdq5c6cCAwMzfW7e3ew8eHezc+Hdzc6DdzcDZla+u/n8Zce9vCMgr7vDzu1IljVHYGCgNm/erP79+2v48OG6kavabDY1b95cM2fOvKMEEQAAAHfPwpxdCg4O1ooVK3T+/HkdOXJEhmGoQoUKCggIsDIsAAAAl2dpknhDQECA7rvvPqvDAAAALooRIGa8lg8AAAAmTlFJBAAAsBLzJJqRJAIAAJdHd7MZ3c0AAAAwoZIIAABcHoVEMyqJAAAAMKGSCAAAQCnRhEoiAAAATKgkAgAAl8cUOGZUEgEAAGBCJREAALg85kk0o5IIAAAAEyqJAADA5VFINCNJBAAAIEs0obsZAAAAJiSJAADA5dkc+M+dmDlzpu655x75+PjogQce0LZt27L4E98eSSIAAIAT+fzzzxUZGamxY8dq586dqlGjhpo3b67Tp09naxwkiQAAwOXZbI5bMmvq1Knq06ePnnjiCYWGhmr27NnKmzevPvzww6z/4P+CJBEAAMCBkpOTlZiYmG5JTk6+6b4pKSnasWOHmjZtal/n5uampk2bKiYmJrtClpRLn272yQWfKjk5WVFRURo+fLi8vb2tDueOJa0faXUIdy23tEVuQFs4D9rCudAed8+RucO4SVEaP358unVjx47VuHHjTPuePXtWqampCgwMTLc+MDBQBw4ccFyQN2EzDMPI1isiQxITE+Xn56eEhAT5+vpaHY5Loy2cB23hPGgL50J7OLfk5GRT5dDb2/umCf2JEydUokQJbd68WWFhYfb1Q4cO1YYNG7R161aHx3tDLqi5AQAAOK9bJYQ3U7hwYbm7u+vUqVPp1p86dUrFihVzRHi3xJhEAAAAJ+Hl5aXatWtr3bp19nVpaWlat25duspidqCSCAAA4EQiIyPVq1cv1alTR/fff7+mTZumS5cu6YknnsjWOEgSnZS3t7fGjh3LAGQnQFs4D9rCedAWzoX2yF26dOmiM2fOaMyYMYqLi1PNmjW1atUq08MsjsaDKwAAADBhTCIAAABMSBIBAABgQpIIAAAAE5LEbGCz2bRs2TKrw4BoC2dCWzgX2sN50BZwFiSJdykuLk6DBg1S2bJl5e3trVKlSqlNmzbp5jeykmEYGjNmjIoXL648efKoadOmOnz4sNVhOYSzt8XSpUsVHh6uQoUKyWazaffu3VaH5DDO3BZXr17VsGHDVK1aNeXLl09BQUHq2bOnTpw4YXVoDuPM7SFJ48aNU6VKlZQvXz4FBASoadOm2fpWiezk7G3xd88884xsNpumTZtmdSiwCFPg3IVff/1V9erVk7+/v6ZMmaJq1arp6tWr+vbbbzVgwIBsf8fizbz22muaPn265s2bpzJlymj06NFq3ry5fv75Z/n4+FgdXpbJCW1x6dIl1a9fX507d1afPn2sDsdhnL0tLl++rJ07d2r06NGqUaOGzp8/r+eff15t27bVjz/+aGlsjuDs7SFJFStW1IwZM1S2bFklJSUpOjpa4eHhOnLkiIoUKWJ1eFkmJ7TFDV988YW2bNmioKAgq0OBlQzcsZYtWxolSpQwLl68aNp2/vx5+79LMr744gv7z0OHDjUqVKhg5MmTxyhTpowxatQoIyUlxb599+7dRqNGjYz8+fMbBQoUMGrVqmVs377dMAzD+PXXX42IiAjD39/fyJs3rxEaGmp88803N40vLS3NKFasmDFlyhT7ugsXLhje3t7Gp59+epef3rk4e1v8XWxsrCHJ2LVr1x1/XmeWk9rihm3bthmSjN9++y3zH9jJ5cT2SEhIMCQZa9euzfwHdmI5pS3++OMPo0SJEsb+/fuN4OBgIzo6+q4+N3IuKol36Ny5c1q1apVeeeUV5cuXz7Td39//lscWKFBAc+fOVVBQkPbt26c+ffqoQIECGjp0qCSpR48euvfeezVr1iy5u7tr9+7d8vT0lCQNGDBAKSkp2rhxo/Lly6eff/5Z+fPnv+l1YmNjFRcXp6ZNm9rX+fn56YEHHlBMTIy6du16F9+A88gJbeEqcmpbJCQkyGaz/Wt8OVFObI+UlBS9++678vPzU40aNTL/oZ1UTmmLtLQ0Pf744xoyZIiqVKlydx8aOZ/VWWpOtXXrVkOSsXTp0tvuq3/8VfhPU6ZMMWrXrm3/uUCBAsbcuXNvum+1atWMcePGZSjGH374wZBknDhxIt36Tp06GZ07d87QOXKCnNAWf5ebK4k5rS0MwzCSkpKMWrVqGd27d7+j451ZTmqPr7/+2siXL59hs9mMoKAgY9u2bZk63tnllLaYPHmy0axZMyMtLc0wDINKoovjwZU7ZNzFi2o+//xz1atXT8WKFVP+/Pk1atQoHT9+3L49MjJSTz/9tJo2bapXX31VR48etW977rnnNGnSJNWrV09jx47V3r177+pz5Aa0hfPIaW1x9epVde7cWYZhaNasWXccu7PKSe3RuHFj7d69W5s3b1aLFi3UuXNnnT59+o7jdzY5oS127NihN998U3PnzpXNZrvjeJGLWJmh5mTx8fGGzWYzJk+efNt99be/Cjdv3my4u7sbkyZNMrZv324cOnTImDBhguHn55fumIMHDxpTp041mjVrZnh5eaX76/P48ePGrFmzjA4dOhienp7G9OnTb3rdo0eP3rRi1aBBA+O5557L1Od1ZjmhLf4uN1cSc1JbpKSkGO3btzeqV69unD17NtOfNSfISe3xT+XLl89Q3DlFTmiL6Ohow2azGe7u7vZFkuHm5mYEBwff6UdHDkaSeBdatGiR6UHIr7/+ulG2bNl0+z711FOm/+H/rmvXrkabNm1uuu3ll182qlWrdtNtNx5cef311+3rEhIScuWDK87eFn+Xm5NEw8gZbXEjQaxSpYpx+vTpW3+YXCAntMfNlC1b1hg7dmymjnF2zt4WZ8+eNfbt25duCQoKMoYNG2YcOHDg3z8cciW6m+/CzJkzlZqaqvvvv19LlizR4cOH9csvv2j69OkKCwu76TEVKlTQ8ePH9dlnn+no0aOaPn26vvjiC/v2pKQkDRw4UN9//71+++03/fDDD9q+fbsqV64sSXrhhRf07bffKjY2Vjt37tR3331n3/ZPNptNL7zwgiZNmqSvvvpK+/btU8+ePRUUFKT27dtn+fdhJWdvC+n6wPXdu3fr559/liQdPHhQu3fvVlxcXBZ+E9Zz9ra4evWqHn30Uf3444+aP3++UlNTFRcXp7i4OKWkpGT9F2IxZ2+PS5cuacSIEdqyZYt+++037dixQ08++aT+/PNPderUKeu/EAs5e1sUKlRIVatWTbd4enqqWLFiCgkJyfovBM7P6iw1pztx4oQxYMAAIzg42PDy8jJKlChhtG3b1vjuu+/s++gfg5CHDBliFCpUyMifP7/RpUsXIzo62v5XYXJystG1a1ejVKlShpeXlxEUFGQMHDjQSEpKMgzDMAYOHGiUK1fO8Pb2NooUKWI8/vjj/9pVlpaWZowePdoIDAw0vL29jSZNmhgHDx50xFdhOWdvizlz5hiSTEtuq5YYhnO3xY1K7s2Wv8eXmzhzeyQlJRkdOnQwgoKCDC8vL6N48eJG27Ztc92DKzc4c1vcDA+uuDabYdzFaFoAAADkSnQ3AwAAwIQkEQAAACYkiQAAADAhSQQAAIAJSSIAAABMSBIBAABgQpIIAAAAE5JEAAAAmJAkAnBavXv3TvcKyUaNGumFF17I9ji+//572Ww2XbhwIduvDQBWIUkEkGm9e/eWzWaTzWaTl5eXypcvrwkTJujatWsOve7SpUs1ceLEDO1LYgcAd8fD6gAA5EwtWrTQnDlzlJycrBUrVmjAgAHy9PTU8OHD0+2XkpIiLy+vLLlmwYIFs+Q8AIDbo5II4I54e3urWLFiCg4OVv/+/dW0aVN99dVX9i7iV155RUFBQQoJCZEk/f777+rcubP8/f1VsGBBtWvXTr/++qv9fKmpqYqMjJS/v78KFSqkoUOH6p+vlv9nd3NycrKGDRumUqVKydvbW+XLl9cHH3ygX3/9VY0bN5YkBQQEyGazqXfv3pKktLQ0RUVFqUyZMsqTJ49q1KihxYsXp7vOihUrVLFiReXJk0eNGzdOFycAuAqSRABZIk+ePEpJSZEkrVu3TgcPHtSaNWu0fPlyXb16Vc2bN1eBAgX03//+Vz/88IPy58+vFi1a2I954403NHfuXH344YfatGmTzp07py+++OJfr9mzZ099+umnmj59un755Re98847yp8/v0qVKqUlS5ZIkg4ePKiTJ0/qzTfflCRFRUXpo48+0uzZs/XTTz/pxRdf1GOPPaYNGzZIup7MduzYUW3atNHu3bv19NNP6+WXX3bU1wYATovuZgB3xTAMrVu3Tt9++60GDRqkM2fOKF++fHr//fft3cyffPKJ0tLS9P7778tms0mS5syZI39/f33//fcKDw/XtGnTNHz4cHXs2FGSNHv2bH377be3vO6hQ4e0cOFCrVmzRk2bNpUklS1b1r79Rtd00aJF5e/vL+l65XHy5Mlau3atwsLC7Mds2rRJ77zzjho2bKhZs2apXLlyeuONNyRJISEh2rdvn/7zn/9k4bcGAM6PJBHAHVm+fLny58+vq1evKi0tTd27d9e4ceM0YMAAVatWLd04xD179ujIkSMqUKBAunNcuXJFR48eVUJCgk6ePKkHHnjAvs3Dw0N16tQxdTnfsHv3brm7u6thw4YZjvnIkSO6fPmymjVrlm59SkqK7r33XknSL7/8ki4OSfaEEgBcCUkigDvSuHFjzZo1S15eXgoKCpKHx//fTvLly5du34sXL6p27dqaP3++6TxFihS5o+vnyZMn08dcvHhRkvTNN9+oRIkS6bZ5e3vfURwAkFuRJAK4I/ny5VP58uUztG+tWrX0+eefq2jRovL19b3pPsWLF9fWrVvVoEEDSdK1a9e0Y8cO1apV66b7V6tWTWlpadqwYYO9u/nvblQyU1NT7etCQ0Pl7e2t48eP37ICWblyZX311Vfp1m3ZsuX2HxIAchkeXAHgcD169FDhwoXVrl07/fe//1VsbKy+//57Pffcc/rjjz8kSc8//7xeffVVLVu2TAcOHNCzzz77r3Mc3nPPPerVq5eefPJJLVu2zH7OhQsXSpKCg4Nls9m0fPlynTlzRhcvXlSBAgX00ksv6cUXX9S8efN09OhR7dy5U2+99ZbmzZsnSXrmmWd0+PBhDRkyRAcPHtSCBQs0d+5cR39FAOB0SBIBOFzevHm1ceNGlS5dWh07dlTlypX11FNP6cqVK/bK4uDBg/X444+rV69eCgsLU4ECBdShQ4d/Pe+sWbP06KOP6tlnn1WlSpXUp08fXbp0SZJUokQJjR8/Xi+//LICAwM1cOBASdLEiRM1evRoRUVFqXLlymrRooW++eYblSlTRpJUunRpLVmyRMuWLVONGjU0e/ZsTZ482YHfDgA4J5txq1HhAAAAcFlUEgEAAGBCkggAAAATkkQAAACYkCQCAADAhCQRAAAAJiSJAAAAMCFJBAAAgAlJIgAAAExIEgEAAGBCkggAAAATkkQAAACY/B/x45YMG8KKDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'], yticklabels=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55b602d9-043f-42b7-9adf-d7dbeb89d586",
   "metadata": {},
   "source": [
    "INTERPRETATION- The model frequently assigns high probabilities to class 1. \n",
    "Fundamental architectural limitations in handling sequential dependencies restrict its reasoning capacity, necessitating structural enhancements for improved semantic comprehension."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e1e2578-7379-4332-93b5-f5746def8b25",
   "metadata": {},
   "source": [
    "Improvement- will try Attention Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c9eae-cf93-4470-9019-bf0b68990285",
   "metadata": {},
   "outputs": [],
   "source": [
    "PART-2 : A 2-layer RNN architecture (LSTM, using the PyTorch implementations), and a two-layer \n",
    "classifier with a ReLU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e65dceb-9e63-4e15-9aba-f0db7cc58b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 68\n",
      "Average length: 16.433771879647637\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for example in train_dataset:\n",
    "    for choice in example['choices']['text']:\n",
    "        combined = example['question'] + choice\n",
    "        lengths.append(len(combined))\n",
    "\n",
    "print(\"Max length:\", max(lengths))\n",
    "print(\"Average length:\", sum(lengths) / len(lengths))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69639b35-5920-4023-a9bd-2a77e7ba39ea",
   "metadata": {},
   "source": [
    "Padding:\n",
    "Since different (question + choice) pairs have different lengths (number of tokens), we pad shorter sequences with a special <pad> token to match the longest one in the batch. This gives us uniform shape: (batch_size, max_seq_len, embedding_dim).\n",
    "Truncation:\n",
    "If a (Q + choice) token sequence is too long, we truncate it to a maximum length (e.g., max_seq_len = 30) to avoid memory issues and maintain efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507642d7-4ee8-4b5b-8801-ad452f8ca79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class CommonsenseQARNNDataset(Dataset):\n",
    "    def __init__(self, dataset, fasttext_model, answer_map={'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}, max_length=32):\n",
    "        self.dataset = dataset\n",
    "        self.ft_model = fasttext_model\n",
    "        self.answer_map = answer_map\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def pad_or_truncate(self, tokens):\n",
    "        if len(tokens) > self.max_length:\n",
    "            return tokens[:self.max_length]\n",
    "        else:\n",
    "            return tokens + ['<PAD>'] * (self.max_length - len(tokens))\n",
    "\n",
    "    def get_embedding(self, tokens):\n",
    "        vectors = []\n",
    "        for token in tokens:\n",
    "            # Check if the token is in the FastText vocabulary\n",
    "            if token in self.ft_model.key_to_index:  # `key_to_index` is used for checking vocab\n",
    "                vectors.append(torch.tensor(self.ft_model[token]))  # Retrieve word vector\n",
    "            else:\n",
    "                # If the token is not in vocabulary, use a zero vector\n",
    "                vectors.append(torch.zeros(300))  # FastText embeddings are of size 300\n",
    "        return torch.stack(vectors)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        question = item['question']\n",
    "        choices = item['choices']['text']\n",
    "        answer = item['answerKey']\n",
    "\n",
    "        sequences = []\n",
    "        for choice in choices:\n",
    "            combined = question + choice\n",
    "            emb = self.get_embedding(combined)  # → (max_len, 300)\n",
    "            sequences.append(emb)\n",
    "\n",
    "        label = self.answer_map[answer]\n",
    "\n",
    "        return {'sequences': sequences, 'label': torch.tensor(label, dtype=torch.long)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b4034af-7ae7-47dc-a782-3774fc50b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_collate_fn(batch, max_len=22):\n",
    "    padded_sequences = []\n",
    "    labels = []\n",
    "\n",
    "    for sample in batch:\n",
    "        padded_choices = []\n",
    "        for seq in sample['sequences']:\n",
    "            # Truncate sequences that are too long\n",
    "            if seq.shape[0] > max_len:\n",
    "                seq = seq[:max_len]\n",
    "            # Pad sequences that are too short\n",
    "            elif seq.shape[0] < max_len:\n",
    "                pad = torch.zeros(max_len - seq.shape[0], 300)\n",
    "                seq = torch.cat([seq, pad], dim=0)\n",
    "            padded_choices.append(seq)\n",
    "        \n",
    "        # Stack the padded choices for this sample (5, max_len, 300)\n",
    "        padded_sequences.append(torch.stack(padded_choices))  # (5, max_len, 300)\n",
    "        labels.append(sample['label'])\n",
    "\n",
    "    return {\n",
    "        'sequences': torch.stack(padded_sequences),  # (batch_size, 5, max_len, 300)\n",
    "        'labels': torch.stack(labels)                # (batch_size,)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82b7aaa0-b4fb-4458-a886-fb67a56c994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CommonsenseQARNNDataset(train_dataset, fasttext_model=fasttext_model)\n",
    "valid_ds = CommonsenseQARNNDataset(valid_dataset, fasttext_model=fasttext_model)\n",
    "test_ds = CommonsenseQARNNDataset(test_dataset, fasttext_model=fasttext_model)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=rnn_collate_fn)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=32, collate_fn=rnn_collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, collate_fn=rnn_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f56f8d-0bef-461b-bf16-f1bc556085b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Architecture-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae10dbf-cf38-456b-8a74-3045ac3a0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing: Join question + each choice → tokenize → get FastText embeddings → pad sequences.  \n",
    "Input to Model: Shape (5, seq_len, 300) → 5 tokenized Q+choice pairs per sample.  \n",
    "Model: Pass through 2-layer LSTM/GRU → extract final hidden state → 2-layer classifier.  \n",
    "Output: Softmax over logits → probability over 5 choices → predicted label (0–4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57adf800-54be-4847-92a0-7e69df82833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=300, hidden_dim=256, num_layers=2, num_choices=5):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_choices = num_choices\n",
    "\n",
    "        # 2-layer LSTM (as specified)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "\n",
    "        # 2-layer classifier with ReLU (as specified)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)  # 1 logit per choice\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Process all 5 choices in parallel maintaining batch structure\n",
    "        Args:\n",
    "            x: (batch_size, 5, seq_len, 300)\n",
    "        Returns:\n",
    "            logits: (batch_size, 5)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Process each choice independently\n",
    "        choice_logits = []\n",
    "        for i in range(self.num_choices):\n",
    "            # Process one choice at a time\n",
    "            choice_seq = x[:, i, :, :]  # (batch_size, seq_len, 300)\n",
    "            \n",
    "            # 2-layer LSTM processing\n",
    "            _, (hidden, _) = self.rnn(choice_seq)  # hidden: (num_layers, batch_size, hidden_dim)\n",
    "            final_hidden = hidden[-1]  # (batch_size, hidden_dim)\n",
    "            \n",
    "            # 2-layer classifier\n",
    "            logit = self.classifier(final_hidden)  # (batch_size, 1)\n",
    "            choice_logits.append(logit)\n",
    "        \n",
    "        # Combine all choices\n",
    "        logits = torch.cat(choice_logits, dim=1)  # (batch_size, 5)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8885e7a8-f902-4694-a0f9-9c50ee793522",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f10ae274-93d3-4c6d-aa4b-ac3181b8f107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▁</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>loss</td><td>▁█</td></tr><tr><td>val_accuracy</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.19357</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>1.60921</td></tr><tr><td>val_accuracy</td><td>0.205</td></tr><tr><td>val_loss</td><td>1.60916</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rnn-train-1</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/8954pmwh' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/8954pmwh</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_025035-8954pmwh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_035742-z6x75pcd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/z6x75pcd' target=\"_blank\">rnn-train-1</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/z6x75pcd' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/z6x75pcd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/z6x75pcd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6a40bc8d40>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    project='CQA_Model-2',\n",
    "    name='rnn-train-1',\n",
    "    config={\n",
    "        'epochs': 3,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-3,\n",
    "        'hidden_dim': 256,      # RNN hidden size\n",
    "        'embedding_dim': 300,   # FastText\n",
    "        'rnn_layers': 2,\n",
    "        'rnn_type': 'LSTM',   \n",
    "        'dropout': 0.3,\n",
    "        'num_classes': 5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9acf8c4e-3ac0-4f6f-8587-1d3c2fcf8b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a695d39-1490-46f7-b737-730b62b355e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb_rnn(model, train_loader, val_loader=None, epochs=3):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Add gradient clipping\n",
    "    max_grad_norm = 1.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = batch['sequences'].to(device)  # (B,5,seq,300)\n",
    "            labels = batch['labels'].to(device)     # (B,)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)  # (B,5)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Logging\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        acc = correct / total\n",
    "        wandb.log({'train_loss': avg_loss, 'train_acc': acc})\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Acc: {acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        if val_loader:\n",
    "            validate_with_wandb(model, val_loader, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28291ffd-0acd-4b71-99c1-c2926b84aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_with_wandb(model, val_loader, loss_fn):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = batch['sequences'].to(device)  # (B,5,seq,300)\n",
    "            labels = batch['labels'].to(device)     # (B,)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    val_loss = total_loss / len(val_loader)\n",
    "    val_acc = correct / total\n",
    "    wandb.log({'val_loss': val_loss, 'val_acc': val_acc})\n",
    "    print(f\"Validation | Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "242ba869-8d90-48db-852c-8d1b95e934bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 5, 22, 300])\n",
      "Label shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Sample batch verification\n",
    "for batch in train_loader:\n",
    "    print(f\"Input shape: {batch['sequences'].shape}\")  # Should be (B,5,seq_len,300)\n",
    "    print(f\"Label shape: {batch['labels'].shape}\")     # Should be (B,)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71a18d0c-1607-4f1e-a345-d93a1b9fd332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 1.6091 | Acc: 0.2005\n",
      "Validation | Loss: 1.6065 | Acc: 0.1940\n",
      "Epoch 2/3 | Loss: 1.6064 | Acc: 0.2111\n",
      "Validation | Loss: 1.6093 | Acc: 0.2040\n",
      "Epoch 3/3 | Loss: 1.6053 | Acc: 0.2124\n",
      "Validation | Loss: 1.6327 | Acc: 0.2020\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = RNNClassifier().to(device)\n",
    "\n",
    "train_with_wandb_rnn(model, train_loader, val_loader=valid_loader, epochs=wandb.config.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "389c4502-797c-4393-b412-4e7ef7e56873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 05:14:50,794] A new study created in memory with name: no-name-3d940028-fe98-4b6f-9c6f-dc33ca451e16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▇█</td></tr><tr><td>train_loss</td><td>█▃▁</td></tr><tr><td>val_acc</td><td>▁█▇</td></tr><tr><td>val_loss</td><td>▁▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>0.21245</td></tr><tr><td>train_loss</td><td>1.6053</td></tr><tr><td>val_acc</td><td>0.202</td></tr><tr><td>val_loss</td><td>1.63265</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rnn-train-1</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/z6x75pcd' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2/runs/z6x75pcd</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_035742-z6x75pcd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_051450-11mlqxj1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/11mlqxj1' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/11mlqxj1' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/11mlqxj1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 Epoch 1/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6093\n",
      "Train Acc: 0.1890 | Val Acc: 0.1940\n",
      "Trial 0 Epoch 2/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6093\n",
      "Train Acc: 0.1964 | Val Acc: 0.2070\n",
      "Trial 0 Epoch 3/3\n",
      "Train Loss: 1.6092 | Val Loss: 1.6086\n",
      "Train Acc: 0.1932 | Val Acc: 0.2080\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>▁█▅</td></tr><tr><td>train_loss</td><td>▇█▁</td></tr><tr><td>val_accuracy</td><td>▁▇█</td></tr><tr><td>val_loss</td><td>█▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.19323</td></tr><tr><td>train_loss</td><td>1.60924</td></tr><tr><td>val_accuracy</td><td>0.208</td></tr><tr><td>val_loss</td><td>1.60864</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/11mlqxj1' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/11mlqxj1</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_051450-11mlqxj1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 05:33:03,345] Trial 0 finished with value: 0.208 and parameters: {'lr': 0.0005613400338386438, 'batch_size': 32, 'hidden_dim': 418, 'weight_decay': 9.390485922306709e-05, 'num_layers': 1, 'dropout': 0.3556365484117382}. Best is trial 0 with value: 0.208.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_053303-o46umand</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/o46umand' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/o46umand' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/o46umand</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Epoch 1/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.2008 | Val Acc: 0.2130\n",
      "Trial 1 Epoch 2/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1851 | Val Acc: 0.2000\n",
      "Trial 1 Epoch 3/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1811 | Val Acc: 0.1950\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>█▂▁</td></tr><tr><td>train_loss</td><td>█▆▁</td></tr><tr><td>val_accuracy</td><td>█▃▁</td></tr><tr><td>val_loss</td><td>█▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.1811</td></tr><tr><td>train_loss</td><td>1.60944</td></tr><tr><td>val_accuracy</td><td>0.195</td></tr><tr><td>val_loss</td><td>1.60944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/o46umand' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/o46umand</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_053303-o46umand/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 05:52:10,179] Trial 1 finished with value: 0.213 and parameters: {'lr': 8.36639865019827e-05, 'batch_size': 32, 'hidden_dim': 470, 'weight_decay': 0.0002745372409990082, 'num_layers': 3, 'dropout': 0.4584721764825156}. Best is trial 1 with value: 0.213.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_055210-a8vobvha</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/a8vobvha' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/a8vobvha' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/a8vobvha</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Epoch 1/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1967 | Val Acc: 0.2000\n",
      "Trial 2 Epoch 2/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1955 | Val Acc: 0.2000\n",
      "Trial 2 Epoch 3/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1955 | Val Acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>█▁▁</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.19552</td></tr><tr><td>train_loss</td><td>1.60944</td></tr><tr><td>val_accuracy</td><td>0.2</td></tr><tr><td>val_loss</td><td>1.60944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/a8vobvha' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/a8vobvha</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_055210-a8vobvha/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 06:00:52,262] Trial 2 finished with value: 0.2 and parameters: {'lr': 0.0030563422234351208, 'batch_size': 64, 'hidden_dim': 432, 'weight_decay': 4.6414472155966004e-05, 'num_layers': 3, 'dropout': 0.15669818225254933}. Best is trial 1 with value: 0.213.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_060052-z772s6es</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/z772s6es' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/z772s6es' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/z772s6es</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Epoch 1/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1912 | Val Acc: 0.1960\n",
      "Trial 3 Epoch 2/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1922 | Val Acc: 0.1940\n",
      "Trial 3 Epoch 3/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1964 | Val Acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>▁▂█</td></tr><tr><td>train_loss</td><td>▁██</td></tr><tr><td>val_accuracy</td><td>▃▁█</td></tr><tr><td>val_loss</td><td>▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.19643</td></tr><tr><td>train_loss</td><td>1.60944</td></tr><tr><td>val_accuracy</td><td>0.2</td></tr><tr><td>val_loss</td><td>1.60944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/z772s6es' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/z772s6es</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_060052-z772s6es/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 06:25:07,330] Trial 3 finished with value: 0.2 and parameters: {'lr': 0.00011086744664184443, 'batch_size': 16, 'hidden_dim': 509, 'weight_decay': 0.00011796802453665688, 'num_layers': 2, 'dropout': 0.1028411692852132}. Best is trial 1 with value: 0.213.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_062507-j1ekj6j0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/j1ekj6j0' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/j1ekj6j0' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/j1ekj6j0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Epoch 1/3\n",
      "Train Loss: 1.6095 | Val Loss: 1.6094\n",
      "Train Acc: 0.1865 | Val Acc: 0.2000\n",
      "Trial 4 Epoch 2/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1955 | Val Acc: 0.2000\n",
      "Trial 4 Epoch 3/3\n",
      "Train Loss: 1.6094 | Val Loss: 1.6094\n",
      "Train Acc: 0.1955 | Val Acc: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_accuracy</td><td>▁██</td></tr><tr><td>train_loss</td><td>█▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_accuracy</td><td>0.19552</td></tr><tr><td>train_loss</td><td>1.60944</td></tr><tr><td>val_accuracy</td><td>0.2</td></tr><tr><td>val_loss</td><td>1.60944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/j1ekj6j0' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna/runs/j1ekj6j0</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Optuna</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_062507-j1ekj6j0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-08 06:42:21,744] Trial 4 finished with value: 0.2 and parameters: {'lr': 0.009902189877236867, 'batch_size': 32, 'hidden_dim': 226, 'weight_decay': 6.492456899040013e-05, 'num_layers': 2, 'dropout': 0.19361228753817794}. Best is trial 1 with value: 0.213.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Hyperparameters to tune (expanded for RNN-specific params)\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('lr', 1e-5, 1e-2, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'hidden_dim': trial.suggest_int('hidden_dim', 128, 512),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True),\n",
    "        'num_layers': trial.suggest_int('num_layers', 1, 3),  # RNN-specific\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.5)   # RNN-specific\n",
    "    }\n",
    "    \n",
    "    # Initialize W&B\n",
    "    wandb.init(\n",
    "        project='CQA_Model-2_Optuna',\n",
    "        name=f'trial_{trial.number}',\n",
    "        config={\n",
    "            **params,\n",
    "            'epochs': 3,\n",
    "            'embedding_dim': 300,\n",
    "            'num_classes': 5,\n",
    "            'rnn_type': 'LSTM'\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    # Create loaders with dynamic batch size\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=rnn_collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds,\n",
    "        batch_size=params['batch_size'],\n",
    "        collate_fn=rnn_collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize RNN model with trial parameters\n",
    "    model = RNNClassifier(\n",
    "        hidden_dim=params['hidden_dim'],\n",
    "        num_layers=params['num_layers']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer with weight decay\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=params['learning_rate'],\n",
    "        weight_decay=params['weight_decay']\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for epoch in range(3):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss, train_correct, train_total = 0, 0, 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            inputs = batch['sequences'].to(device, non_blocking=True)\n",
    "            labels = batch['labels'].to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            with torch.no_grad():\n",
    "                _, predicted = outputs.max(dim=1)\n",
    "                correct = (predicted == labels).sum().item()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_correct += correct\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                inputs = batch['sequences'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                # Calculate validation loss\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, predicted = outputs.max(dim=1)\n",
    "                correct = (predicted == labels).sum().item()\n",
    "                \n",
    "                val_correct += correct\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        val_loss = val_loss / len(valid_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Log metrics\n",
    "        wandb.log({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_accuracy': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_acc\n",
    "        })\n",
    "        \n",
    "        print(f\"Trial {trial.number} Epoch {epoch+1}/3\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Track best validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "    wandb.finish()\n",
    "    return best_val_acc\n",
    "\n",
    "# Run study with enhanced settings\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    "    pruner=optuna.pruners.HyperbandPruner()\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=5, gc_after_trial=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b3b63b3-b010-4809-9711-f8d48105f628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 8.36639865019827e-05,\n",
       " 'batch_size': 32,\n",
       " 'hidden_dim': 470,\n",
       " 'weight_decay': 0.0002745372409990082,\n",
       " 'num_layers': 3,\n",
       " 'dropout': 0.4584721764825156}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29a853a5-83ed-4b31-a4bc-810e2f531cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">arch2_final_run</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final/runs/4mueye4p' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final/runs/4mueye4p</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_070000-4mueye4p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_070247-u8pr4x4f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final/runs/u8pr4x4f' target=\"_blank\">arch2_final_run</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final/runs/u8pr4x4f' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final/runs/u8pr4x4f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 | Loss: 1.6094 | Acc: 0.1892\n",
      "Epoch 2/3 | Loss: 1.6094 | Acc: 0.1861\n",
      "Epoch 3/3 | Loss: 1.6094 | Acc: 0.1885\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>train_acc</td><td>█▁▆</td></tr><tr><td>train_loss</td><td>█▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>train_acc</td><td>0.18848</td></tr><tr><td>train_loss</td><td>1.60944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">arch2_final_run</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final/runs/u8pr4x4f' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final/runs/u8pr4x4f</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Final</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_070247-u8pr4x4f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train final model with best params (ARCH 2)\n",
    "best_params = study.best_params\n",
    "\n",
    "wandb.init(\n",
    "    project='CQA_Model-2_Final',\n",
    "    config={\n",
    "        **best_params,\n",
    "        'epochs': 3,\n",
    "        'embedding_dim': 300,\n",
    "        'num_classes': 5\n",
    "    },\n",
    "    name='arch2_final_run'\n",
    ")\n",
    "\n",
    "# Initialize final model with best params\n",
    "final_model = RNNClassifier(\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    num_layers=best_params['num_layers']\n",
    ").to(device)\n",
    "\n",
    "# Use entire training data (train + valid)\n",
    "full_train_dataset = torch.utils.data.ConcatDataset([train_ds, valid_ds])\n",
    "full_train_loader = DataLoader(\n",
    "    full_train_dataset,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    shuffle=True,\n",
    "    collate_fn=rnn_collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Optimizer with best params\n",
    "optimizer = optim.Adam(\n",
    "    final_model.parameters(),\n",
    "    lr=best_params['lr'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "# Train with existing function (modified for full dataset)\n",
    "def train_with_wandb_rnn_final(model, train_loader, epochs=3):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = batch['sequences'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Metrics\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Logging\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        acc = correct / total\n",
    "        wandb.log({\n",
    "            'epoch': epoch+1,\n",
    "            'train_loss': avg_loss,\n",
    "            'train_acc': acc\n",
    "        })\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Acc: {acc:.4f}\")\n",
    "\n",
    "train_with_wandb_rnn_final(final_model, full_train_loader, epochs=3)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "340e211a-f826-4eaa-b00d-4d947827b646",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1769e0f9-bf14-479f-9be6-df60f8ec3f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/wandb/run-20250408_075103-co4nv572</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation/runs/co4nv572' target=\"_blank\">arch2_final_evaluation</a></strong> to <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation/runs/co4nv572' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation/runs/co4nv572</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.1908\n",
      "Precision: 0.1807\n",
      "Recall: 0.1937\n",
      "F1 Score: 0.0991\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>f1</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.19083</td></tr><tr><td>f1</td><td>0.09911</td></tr><tr><td>precision</td><td>0.18072</td></tr><tr><td>recall</td><td>0.19373</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">arch2_final_evaluation</strong> at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation/runs/co4nv572' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation/runs/co4nv572</a><br> View project at: <a href='https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation' target=\"_blank\">https://wandb.ai/aditi-sharma-00073-hochschule-luzern/CQA_Model-2_Evaluation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250408_075103-co4nv572/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# Initialize W&B for logging\n",
    "wandb.init(\n",
    "    project='CQA_Model-2_Evaluation',\n",
    "    config={\n",
    "        'model_type': 'RNN',\n",
    "        'test_batch_size': 32,\n",
    "        'embedding_dim': 300,\n",
    "        'num_classes': 5\n",
    "    },\n",
    "    name='arch2_final_evaluation'\n",
    ")\n",
    "\n",
    "# Prediction on test set\n",
    "final_model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "final_model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['sequences'].to(device)\n",
    "        targets = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = final_model(inputs)\n",
    "        _, predicted = outputs.max(dim=1)\n",
    "        \n",
    "        y_true.extend(targets.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "# Log to W&B\n",
    "wandb.log({\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1\n",
    "})\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Close W&B run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a0da0be5-fbcb-423a-b23d-88bf6e04c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['sequences'].to(device)\n",
    "        targets = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = final_model(inputs)\n",
    "        _, predicted = outputs.max(dim=1)\n",
    "        \n",
    "        incorrect_indices = (predicted != targets).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        for idx in incorrect_indices:\n",
    "            misclassified.append((\n",
    "                inputs[idx].cpu().numpy(),  # Full sequence (5,seq,300)\n",
    "                targets[idx].cpu().numpy(),\n",
    "                predicted[idx].cpu().numpy()\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "288669fa-daff-4a67-8337-526358fa535a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['A','B','C','D','E'],\n",
    "            yticklabels=['A','B','C','D','E'])\n",
    "plt.title('ARCH2 Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d338d0-852d-47a0-ac1c-8a637424d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERPRETATION-"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62cc2164-ee83-45a5-84e3-81da646c3475",
   "metadata": {},
   "source": [
    "The model struggles to correctly identify relevant instances across all classes. The confusion matrix shows the model has a strong bias towards predicting class 'A,' regardless of the actual true label. Very few instances of other classes are correctly classified. This indicates a significant problem with the model's ability to learn the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12531e0-a9e9-42ee-aac7-c9bc8c37e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONCLUSION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "486daad3-066f-4fcd-bc1f-b0433ac9cb90",
   "metadata": {},
   "source": [
    "Both Model 1 and 2 demonstrate poor performance on the commonsense question-answering task, with accuracy scores of 20.56% and 19.08%, respectively. Model 1 exhibits low precision (7.20%) but a relatively higher recall (19.70%), indicating that while it captures a considerable portion of the relevant instances, it also produces a high number of false positives. In contrast, Model 2 shows a slightly improved precision (18.07%) with a comparable recall (19.37%), but its F1-score remains low due to the low precision. The primary limitation of both models lies in their inability to accurately discern the correct answer choice given the question and context. The provided confusion matrix for ARCH2 further reveals a strong bias towards predicting class 'A,' indicating a significant deficiency in learning the nuances of the task. Efforts should focus on architectural improvements, refined training methodologies, and more effective hyperparameter tuning to address these shortcomings and enhance performance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "733a1e6b-5e01-41a6-aee0-6f743cf0d646",
   "metadata": {},
   "source": [
    "Scope for Improvement- Attention Mechanisms: Supplementing the RNN with attention mechanisms might allow the model to focus on the most relevant parts of the input sequence, improving its ability to handle non-sequential relationships."
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bbe4231-b50d-4117-8225-3062147c8d6a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "095ab20b-a35b-483f-9c2f-16a3b4a98307",
   "metadata": {},
   "source": [
    "Tools used for debugging and code completion : ChatGPT and Perplexity AI\n",
    "Project Discussion notes from ilias referred."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bd0212b-612a-44ef-b54d-9b0d2a3c0db7",
   "metadata": {},
   "source": [
    "thankyou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
